{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whitney Kenner\n",
    "u0777962\n",
    "HW4\n",
    "CS6017\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "ddf = pd.read_csv('timing.csv')\n",
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#begin analyzing by comparing only the impact of K on all dataStructures\n",
    "k_variable_gaussian_df = ddf.loc[(ddf['testType'] == 'k') & (ddf['distribution'] == 'G')]\n",
    "\n",
    "\n",
    "sns.scatterplot(y='time',x='kVal',hue='structType',data=k_variable_gaussian_df).set(title='Effect of variable K on 3 data structs (gaussian dist)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "#compare time + kVal gaussian for each data struct (only done on gaussian distributions):\n",
    "#bucket\n",
    "k_variable_g_df_bucket = k_variable_gaussian_df.loc[(k_variable_gaussian_df['structType'] == 'bucket')]\n",
    "k_variable_g_b_ols = sm.ols(formula=\"time ~ kVal\", data=k_variable_g_df_bucket).fit()\n",
    "k_variable_g_b_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quadTree\n",
    "k_variable_g_df_quad = k_variable_gaussian_df.loc[(k_variable_gaussian_df['structType'] == 'quad')]\n",
    "k_variable_g_q_ols = sm.ols(formula=\"time ~ kVal\", data=k_variable_g_df_quad).fit()\n",
    "k_variable_g_q_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KDTree\n",
    "k_variable_g_df_kd = k_variable_gaussian_df.loc[(k_variable_gaussian_df['structType'] == 'kd')]\n",
    "k_variable_g_k_ols = sm.ols(formula=\"time ~ kVal\", data=k_variable_g_df_kd).fit()\n",
    "k_variable_g_k_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now will look at the impact of variable K on uniform distribution\n",
    "k_variable_uniform_df = ddf.loc[(ddf['testType'] == 'k') & (ddf['distribution'] == 'U')]\n",
    "\n",
    "\n",
    "sns.scatterplot(y='time',x='kVal',hue='structType',data=k_variable_uniform_df).set(title='Effect of variable K on 3 data structs (uniform dist)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impact of n on gaussian distribution\n",
    "n_variable_gaussian_df = ddf.loc[(ddf['testType'] == 'n') & (ddf['distribution'] == 'G')]\n",
    "\n",
    "\n",
    "sns.scatterplot(y='time',x='nVal',hue='structType',data=n_variable_gaussian_df).set(title='Effect of variable N on 3 data structs (gaussian dist)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare time + nVal gaussian for each data struct (only done on gaussian distributions):\n",
    "#bucket\n",
    "n_variable_g_df_bucket = n_variable_gaussian_df.loc[(n_variable_gaussian_df['structType'] == 'bucket')]\n",
    "n_variable_g_b_ols = sm.ols(formula=\"time ~ nVal\", data=n_variable_g_df_bucket).fit()\n",
    "n_variable_g_b_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quad\n",
    "n_variable_g_df_quad = n_variable_gaussian_df.loc[(n_variable_gaussian_df['structType'] == 'quad')]\n",
    "n_variable_g_q_ols = sm.ols(formula=\"time ~ nVal\", data=n_variable_g_df_quad).fit()\n",
    "n_variable_g_q_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KDTree\n",
    "n_variable_g_df_kd = n_variable_gaussian_df.loc[(n_variable_gaussian_df['structType'] == 'kd')]\n",
    "n_variable_g_k_ols = sm.ols(formula=\"time ~ nVal\", data=n_variable_g_df_kd).fit()\n",
    "n_variable_g_k_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impact of n on uniform distribution\n",
    "n_variable_uniform_df = ddf.loc[(ddf['testType'] == 'n') & (ddf['distribution'] == 'U')]\n",
    "\n",
    "\n",
    "sns.scatterplot(y='time',x='nVal',hue='structType',data=n_variable_uniform_df).set(title='Effect of variable N on 3 data structs (uniform dist)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impact of d on gaussian distribution\n",
    "d_variable_gaussian_df = ddf.loc[(ddf['testType'] == 'd') & (ddf['distribution'] == 'G')]\n",
    "\n",
    "\n",
    "sns.scatterplot(y='time',x='dVal',hue='structType',data=d_variable_gaussian_df).set(title='Effect of variable D on 2 data structs (gaussian dist)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare time + dVal gaussian for each data struct (only done on gaussian distributions):\n",
    "#bucket\n",
    "d_variable_g_df_bucket = d_variable_gaussian_df.loc[(d_variable_gaussian_df['structType'] == 'bucket')]\n",
    "d_variable_g_b_ols = sm.ols(formula=\"time ~ dVal\", data=d_variable_g_df_bucket).fit()\n",
    "d_variable_g_b_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kdtree\n",
    "d_variable_g_df_kd = d_variable_gaussian_df.loc[(d_variable_gaussian_df['structType'] == 'bucket')]\n",
    "d_variable_g_k_ols = sm.ols(formula=\"time ~ dVal\", data=d_variable_g_df_kd).fit()\n",
    "d_variable_g_k_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impact of d on uniform distribution\n",
    "d_variable_uniform_df = ddf.loc[(ddf['testType'] == 'd') & (ddf['distribution'] == 'U')]\n",
    "\n",
    "\n",
    "sns.scatterplot(y='time',x='dVal',hue='structType',data=d_variable_uniform_df).set(title='Effect of variable D on 2 data structs (uniform dist)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impact of k + n on gaussian distribution\n",
    "kn_variable_gaussian_df = ddf[(ddf['testType'] == 'kn') & (ddf['distribution'] == 'G')]\n",
    "kn_variable_g_df = pd.DataFrame(kn_variable_gaussian_df)\n",
    "kn_variable_g_df['k+nVal'] = kn_variable_g_df['nVal']+kn_variable_g_df['kVal']\n",
    "sns.scatterplot(y='time',x='k+nVal',hue='structType',data=kn_variable_g_df).set(title='Effect of variables K & N on 3 data structs (gaussian dist)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impact of k + n on uniform distribution\n",
    "kn_variable_uniform_df = ddf[(ddf['testType'] == 'kn') & (ddf['distribution'] == 'U')]\n",
    "kn_variable_u_df = pd.DataFrame(kn_variable_uniform_df)\n",
    "kn_variable_u_df['k+nVal'] = kn_variable_u_df['nVal']+kn_variable_u_df['kVal']\n",
    "sns.scatterplot(y='time',x='k+nVal',hue='structType',data=kn_variable_u_df).set(title='Effect of variables K & N on 3 data structs (uniform dist)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALYSIS\n",
    "\n",
    "Analyze the data you collected.\n",
    "\n",
    "Plot parts of your data to make sense of it (what impact does K, N, D, and the data structure have?)\n",
    "The data structure itself appears to be correlated with the overall time it takes! Overall, KDTree seems to be the most time efficient, which makes sense, but as k + n increase on a gaussian distribution, kdtree seems to perform slightly worse. I'm assuming this is due to an inefficiency in my implementation as it should still perform better. The timing for KDTree is relatively unaffected by increasing dimesions which makes sense due to it splitting each level by dimension, bucketing does NOT handle increasing dimensionality well.  bucketing is extremely slow, particularly as N or K + N increases. No matter the number of neighbors (K), the bucketing structure seems to perform terribly, which makes sense since bucket knn query still has to iterate through all of the points within the given bucket. \n",
    "\n",
    "Perform regression based on the performance we expect to see. Do tests confirm or disprove our expectations? What run times do you expect to see based on simple big-O analysis?\n",
    "Are there any aspects of your data that seem unusual? Can you explain them?\n",
    "\n",
    "Bucket knn overall met my expectations except for on the effects of dimensionality on a uniform distribution, for some reason the timing goes up from 1-4 dimensions and then begins to drop at 5 dimensions. this isn't seen in the gaussian distribution. I repeated the timing numerous times and each time it returned similar values. My best guess is having them uniformly distributed made the buckets more even which slightly reduced the search time, but I don't see how the dimensionality would affect it so greatly. the time complexity of bucket sorting can be as good as O(m log m) with an efficient sorting algorithm, but ours does not appear particularly efficient hence the terrible timing. I was a little surprised that the quad tree performed better than the kd tree in one instance: k + n increasing on a gaussian distribution (as k + n get large). kd tree should have a search big O of (log n) and quad tree should have a search big O of (log n + k), so the quad tree should be less efficient. I wonder if this just happens to be due to the split points for both of the different data structures? re-running various times returns the same result. it could also be due to an inefficency in my implementation somewhere\n",
    "\n",
    "\n",
    "This is pretty open ended. The goal is to use simple visualization and regression to make sense of the timing data that you collect."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
