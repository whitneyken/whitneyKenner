{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Data Science \n",
    "# Lecture 11: Linear Regression 2\n",
    "* Adapted from COMP 5360 / MATH 4100, University of Utah, http://datasciencecourse.net/*\n",
    "\n",
    "In this lecutre, we'll discuss:\n",
    "* overfitting, model generalizability, and the bias-variance tradeoff\n",
    "* cross validation \n",
    "* using categorical variables for regression \n",
    "\n",
    "Recommended reading:\n",
    "* G. James, D. Witten, T. Hastie, and R. Tibshirani, An Introduction to Statistical Learning, Ch. 3 [digitial version available here](http://www-bcf.usc.edu/~gareth/ISL/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review from Lecture 10 (Linear Regression 1)\n",
    "\n",
    "### Simple Linear Regression (SLR)\n",
    "\n",
    "** Data**: We have $n$ samples $(x, y)_i$, $i=1,\\ldots n$. \n",
    "\n",
    "** Model**: $y \\sim \\beta_0 + \\beta_1 x$ \n",
    "\n",
    "**Goal**: Find the best values of $\\beta_0$ and $\\beta_1$, denoted $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$, so that the prediction $y = \\hat{\\beta}_0 + \\hat{\\beta}_1 x$ \"best fits\" the data. \n",
    "\n",
    "<img src=\"438px-Linear_regression.png\", title=\"https://en.wikipedia.org/wiki/Linear_regression\", width=\"40%\">\n",
    "\n",
    "**Theorem.** \n",
    "The parameters that minimize the \"residual sum of squares (RSS)\", \n",
    "$RSS = \\sum_i (y_i - \\beta_0 - \\beta_1 x_i)^2$, \n",
    "are: \n",
    "$$\n",
    "\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y}) }{\\sum_{i=1}^n (x_i - \\overline{x})^2}\n",
    "\\qquad \\textrm{and} \\qquad\n",
    "\\hat{\\beta}_0 = \\overline{y} -  \\hat{\\beta}_1 \\overline{x}. \n",
    "$$\n",
    "where $\\overline{x} = \\frac{1}{n} \\sum_{i=1}^n x_i$ and $\\overline{y} = \\frac{1}{n} \\sum_{i=1}^n y_i$. \n",
    "\n",
    "\n",
    "### Multilinear regression \n",
    "\n",
    "** Data**: We have $n$ samples of the form $\\big(x_1, x_2 , \\ldots, x_m , y \\big)_i$, $i=1,\\ldots n$. \n",
    "\n",
    "** Model**: $y \\sim \\beta_0 + \\beta_1 x_1 + \\cdots \\beta_m x_m $ \n",
    "\n",
    "### Nonlinear relationships  \n",
    "\n",
    "** Data**: We have $n$ samples $\\big(x_1, x_2 , \\ldots, x_m , y \\big)_i$, $i=1,\\ldots n$. \n",
    "\n",
    "** Model**: $y \\sim \\beta_0 + \\beta_1 f_1(x_1,x_2,\\ldots,x_m) + \\cdots \\beta_k f_k(x_1,x_2,\\ldots,x_m)$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression with python\n",
    "\n",
    "There are several different python packages that do regression:\n",
    "1. [statsmodels](http://statsmodels.sourceforge.net/)\n",
    "+ [scikit-learn](http://scikit-learn.org/)\n",
    "+ [SciPy](http://www.scipy.org/)\n",
    "+ ... \n",
    "\n",
    "Last time, I commented that statsmodels approaches regression from a statistics viewpoint, while scikit-learn approaches from a machine learning viewpoint. I'll say more about this today. \n",
    "\n",
    "SciPy has some regression tools, but compared to these other two packages, they are relatively limited. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# imports and setup\n",
    "\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as sm\n",
    "from sklearn import linear_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Advertisement dataset\n",
    "Consider the 'Advertising' dataset from\n",
    "[here](http://www-bcf.usc.edu/~gareth/ISL/data.html).\n",
    "\n",
    "\n",
    "For 200 different ‘markets’ (think different cities), this dataset consists of the number of sales of a particular product as well as the advertising budget for three different media: TV, radio, and newspaper. \n",
    "\n",
    "\n",
    "\n",
    "Last time, after trying a variety of linear models, we discovered the following one, which includes a nonlinear relationship between the TV budget and Radio budget:\n",
    "$$\n",
    "\\text{Sales} = \\beta_0 + \\beta_1 * \\text{TV\\_budget} + \\beta_2*\\text{Radio\\_budget} + \\beta_3 * \\text{TV\\_budget} *\\text{Radio\\_budget}. \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "advert = pd.read_csv('Advertising.csv',index_col=0) #load data\n",
    "\n",
    "ad_NL = sm.ols(formula=\"Sales ~ TV + Radio + TV*Radio\", data=advert).fit()\n",
    "ad_NL.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "This model is really excellent: \n",
    "- $R^2 = 97\\%$ of the variability in the data is accounted for by the model. \n",
    "- The $p$-value for the F-statistic is very small \n",
    "- The $p$-values for the individual coefficients are small \n",
    "\n",
    "Interpretation: \n",
    "- In a particular market, if I spend an additional $1k on TV advertising, what do I expect sales to do? \n",
    "- Should I spend additional money on TV or Radio advertising? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(xs=advert['TV'], ys=advert['Radio'], zs=advert['Sales'])\n",
    "\n",
    "x = np.linspace(advert['TV'].min(), advert['TV'].max(), 100)\n",
    "y = np.linspace(advert['Radio'].min(), advert['Radio'].max(), 100)\n",
    "X,Y = np.meshgrid(x,y)\n",
    "par = dict(ad_NL.params)\n",
    "Z = par[\"Intercept\"] + par[\"TV\"]*X + par[\"Radio\"]*Y + par[\"TV:Radio\"]*X*Y\n",
    "surf = ax.plot_surface(X, Y, Z,cmap=cm.Greys, alpha=0.2)\n",
    "\n",
    "ax.view_init(25,-71)\n",
    "\n",
    "ax.set_xlabel('TV budget')\n",
    "ax.set_ylabel('Radio budget')\n",
    "ax.set_zlabel('Sales')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.arange( -100, 100 )\n",
    "ys = xs + xs**2 + xs**3 + xs**4\n",
    "\n",
    "plt.plot(xs,ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### A word of caution on overfitting\n",
    "\n",
    "It is tempting to include a lot of terms in the regression, but this is problematic (think $p$-hacking.) A useful model will  *generalize* beyond the data given to it. \n",
    "\n",
    "\n",
    "**Questions?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overfitting, underfitting, model generalizability, and the bias–variance tradeoff\n",
    "\n",
    "In regression, and other prediction problems, we would like to develop a model on a dataset, that would preform well, not only on that dataset, but on similar data that the model hasn't yet seen by the model. If a model satisfies this criterion, we would that it is *generalizable*. \n",
    "\n",
    "Consider the following data, that has been fit with a linear polynomial model (black) and a high degree polynomial model (blue). For convenience, let me call these the black and blue models, respectively. \n",
    "\n",
    "![Overfit data](https://upload.wikimedia.org/wikipedia/commons/6/68/Overfitted_Data.png)\n",
    "\n",
    "\n",
    "Let's call the dataset that we train the model on the *training dataset* and the dataset that we test the model on the *testing dataset*. In the above figure, the training dataset are the black points and the testing dataset is not shown, but we imagine it to be similiar to the points shown. \n",
    "\n",
    "Which model is better? \n",
    "\n",
    "The blue model has 100% accuracy on the training dataset, while the black model has much smaller accuracy. However, the blue model is highly oscillatory and might not generalize well to new data. For example, the model would wildly miss the test point $(3,0)$. We say that the blue model has *overfit* the data. On the other hand, it isn't difficult to see that we could also *underfit* the data. In this case, the model isn't complex enough to have good accuracy on the training dataset. \n",
    "\n",
    "This phenomena is often described in terms of the *bias-variance tradeoff*. Here, we decompose the error of the model into three terms:\n",
    "$$\n",
    "\\textrm{Error} = \n",
    "\\textrm{Bias} + \n",
    "\\textrm{Variance} + \n",
    "\\textrm{Irreducible Error}. \n",
    "$$\n",
    "- The *bias* of the method is the error caused by the simplifying assumptions built into the method. \n",
    "+ The *variance* of the method is how much the model will change based on the sampled data. \n",
    "+ The *irreducible error* is error in the data itself, so no model can capture this error. \n",
    "\n",
    "There is a tradeoff between the bias and variance of a model. \n",
    "High-variance methods (e.g., the blue method) are accurate on the training set, but overfit noise in the data, so don't generalized well to new data. High-bias models (e.g., the black method) are too simple to fit the data, but are better at generalizing to new test data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generalizability in practice\n",
    "\n",
    "Consider the Auto dataset, which contains 9 features (mpg, cylinders, displacement, horsepower, weight, acceleration, year, origin, name) for 397 different used cars. This dataset is available digitally here: [link](http://www-bcf.usc.edu/~gareth/ISL/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "auto = pd.read_csv('Auto.csv') #load data\n",
    "\n",
    "#display(auto.dtypes)\n",
    "\n",
    "# one of the horsepowers is '?', so we just remove it and then map the remaining strings to integers\n",
    "auto = auto[auto.horsepower != '?']\n",
    "auto['horsepower'] = auto['horsepower'].map(int)\n",
    "\n",
    "auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(auto.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's consider the relationship between mpg and horsepower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(auto['horsepower'],auto['mpg'],color='black',linewidth=1)\n",
    "plt.xlabel('horsepower'); plt.ylabel('mpg')\n",
    "plt.ylim((0,50))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We consider the linear model\n",
    "$$\n",
    "\\text{mpg} = \\beta_0 + \\beta_1 \\text{horsepower} + \\beta_2 \\text{horsepower}^2 + \\cdots + \\beta_m \\text{horsepower}^m\n",
    "$$\n",
    "It might seem that choosing $m$ to be large would be a good thing. After all, a high degree polynomial is more flexible than a small degree polynomial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# fit polynomial models\n",
    "mr1 = sm.ols(formula=\"mpg ~ horsepower\", data=auto).fit()\n",
    "par1 = dict(mr1.params)\n",
    "mr2 = sm.ols(formula=\"mpg ~ horsepower + I(horsepower ** 2.0)\", data=auto).fit()\n",
    "par2 = dict(mr2.params)\n",
    "mr3 = sm.ols(formula=\"mpg ~ horsepower + I(horsepower ** 2.0) + I(horsepower ** 3.0)\", data=auto).fit()\n",
    "par3 = dict(mr3.params)\n",
    "mr4 = sm.ols(formula=\"mpg ~ horsepower + I(horsepower ** 2.0) + I(horsepower ** 3.0) + I(horsepower ** 4.0)\", data=auto).fit()\n",
    "par4 = dict(mr4.params)\n",
    "\n",
    "plt.scatter(auto['horsepower'],auto['mpg'],color='black',label=\"data\")\n",
    "\n",
    "xs = np.linspace(0,250,1000)\n",
    "y1 = par1[\"Intercept\"] + par1['horsepower']*xs\n",
    "y2 = par2[\"Intercept\"] + par2['horsepower']*xs + par2['I(horsepower ** 2.0)']*xs**2\n",
    "y3 = par3[\"Intercept\"] + par3['horsepower']*xs + par3['I(horsepower ** 2.0)']*xs**2 + par3['I(horsepower ** 3.0)']*xs**3\n",
    "y4 = par4[\"Intercept\"] + par4['horsepower']*xs + par4['I(horsepower ** 2.0)']*xs**2 + par4['I(horsepower ** 3.0)']*xs**3 + par4['I(horsepower ** 4.0)']*xs**4\n",
    "\n",
    "plt.plot( xs, y1, label=\"degree 1\", linewidth=2 )\n",
    "plt.plot( xs, y2, label=\"degree 2\", linewidth=2 )\n",
    "plt.plot( xs, y3, label=\"degree 3\", linewidth=2 )\n",
    "plt.plot( xs, y4, label=\"degree 4\", linewidth=2 )\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('horsepower'); plt.ylabel('mpg')\n",
    "_= plt.ylim((0,50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print( 'Linear:  mr1: %.2f%%' % ( mr1.rsquared * 100 ) )\n",
    "print( 'Quad:    mr2: %.2f%%' % ( mr2.rsquared * 100 ) )\n",
    "print( 'Cubic:   mr3: %.2f%%' % ( mr3.rsquared * 100 ) )\n",
    "print( 'Quartic: mr4: %.2f%%' % ( mr4.rsquared * 100 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As $m$ increases, the $R^2$ value is becoming larger. (You can prove that this is always true if you add more predictors.)\n",
    "\n",
    "Let's check the $p$-values for the coefficients for the degree 4 fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# display( mr1.summary() )\n",
    "#display( mr2.summary() )\n",
    "display( mr4.summary() ) # Large P-values => Indicates overfit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display( mr1.summary() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "For $m>2$, the $p$-values are very large, so we don't have a strong relationship between the variables. \n",
    "\n",
    "We could rely on *Occam's razor* to decide betwee models. Occam's razor can be stated: among many different models that explain the data, the simplest one should be used. Since we don't get much benefit in terms of $R^2$ values by choosing $m>2$, we should use $m=2$. \n",
    "\n",
    "But there are even better crieterion for deciding between models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mr3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-validation\n",
    "\n",
    "There is a clever method for developing generalizable models that aren't underfit or overfit, called *cross valiation*. \n",
    "\n",
    "**Cross-validation** is a general method for assessing how the results of a model (regression, classification,...) will *generalize* to an independent data set. In regression, cross-validation is a method for assessing how well the regression model will predict the dependent value for points that weren't used to *train* the model. \n",
    "\n",
    "The idea of the method is simple: \n",
    "1. Split the dataset into two groups: the training dataset and the testing dataset. \n",
    "+ Train a varierty of model on the training dataset. \n",
    "+ Check the accuracy of each model on the testing dataset. \n",
    "+ By comparing these accuracies, determine which model is best.\n",
    "\n",
    "In practice, you have to decide how to split the data into groups (i.e. how large the groups should be). You might also want to repeat the experiment so that the assessment doesn't depend on the way in which you split the data into groups. We'll worry about these questions in a later lecture.\n",
    "\n",
    "As the model becomes more complex ($m$ increases), the accuracy always increases for the training dataset. But, at some point, it starts to overfit the data and the accuracy decreases for the test dataset! Cross validation techniques will allow us to find the sweet-spot for the parameter $m$! (Think: Goldilocks and the Three Bears.)\n",
    "\n",
    "\n",
    "Let's see this concept for the relationship between mpg and horsepower in the Auto dataset. We'll use the scikit-learn package for the cross validation analysis instead of statsmodels, because it is much easier to do cross validation there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "lr = linear_model.LinearRegression() # create a linear regression object\n",
    "\n",
    "# with scikit-learn, we have to extract values from the pandas dataframe\n",
    "for m in np.arange(2,6): \n",
    "    auto['h'+str(m)] = auto['horsepower']**m\n",
    "\n",
    "X = auto[['horsepower','h2','h3','h4','h5']].values.reshape(auto['horsepower'].shape[0],5)\n",
    "y = auto['mpg'].values.reshape(auto['mpg'].shape[0],1)\n",
    "\n",
    "plt.scatter(X[:,0], y,  color='black',label='data')\n",
    "\n",
    "# make data for plotting\n",
    "xs = np.linspace(20, 250, num=100)\n",
    "Xs = np.zeros([100,5])\n",
    "Xs[:,0] = xs\n",
    "for m in np.arange(1,5): \n",
    "    Xs[:,m] = xs**(m+1)\n",
    "    \n",
    "for m in np.arange(1,6):     \n",
    "    lr.fit(X=X[:,:m], y=y)\n",
    "    plt.plot(xs, lr.predict(X=Xs[:,:m]), linewidth=3, label = \"m = \" + str(m) )\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('horsepower'); plt.ylabel('mpg')\n",
    "plt.ylim((0,50))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Cross validation using scikit-learn \n",
    "\n",
    "- In scikit-learn, you can use the *train_test_split* function to split the dataset into a training dataset and a test dataset.\n",
    "+ The *score* function returns the coefficient of determination, $R^2$, of the prediction.\n",
    "\n",
    "In the following code, I've split the data in an unusual way - taking the test set to be 85% - to illustrate the point more clearly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "plt.scatter(X_train[:,0], y_train,  color='red',label='training data')\n",
    "plt.scatter(X_test[:,0], y_test,  color='black',label='test data')\n",
    "\n",
    "for m in np.arange(1,6):     \n",
    "    lr.fit(X=X_train[:,:m], y=y_train)\n",
    "    print('m = %d, train: %.4f%%, test: %.4f%%' % (m, lr.score(X_train[:,:m], y_train)*100, 100*lr.score(X_test[:,:m], y_test)))\n",
    "    plt.plot(xs, lr.predict(X=Xs[:,:m]), linewidth=3, label = \"m = \" + str(m) )\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('horsepower'); plt.ylabel('mpg')\n",
    "_ = plt.ylim((0,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# fit polynomial models\n",
    "mr1 = sm.ols(formula=\"mpg ~ horsepower\", data=auto).fit()\n",
    "par1 = dict(mr1.params)\n",
    "mr2 = sm.ols(formula=\"mpg ~ horsepower + I(horsepower ** 2.0)\", data=auto).fit()\n",
    "par2 = dict(mr2.params)\n",
    "mr3 = sm.ols(formula=\"mpg ~ horsepower + I(horsepower ** 2.0) + I(horsepower ** 3.0)\", data=auto).fit()\n",
    "par3 = dict(mr3.params)\n",
    "mr4 = sm.ols(formula=\"mpg ~ horsepower + I(horsepower ** 2.0) + I(horsepower ** 3.0) + I(horsepower ** 4.0)\", data=auto).fit()\n",
    "par4 = dict(mr4.params)\n",
    "mr5 = sm.ols(formula=\"mpg ~ horsepower + I(horsepower ** -1.0)\", data=auto).fit()\n",
    "par5 = dict(mr5.params)\n",
    "mr6 = sm.ols(formula=\"mpg ~ horsepower + I(horsepower ** -1.0) + I(horsepower ** -2.0)\", data=auto).fit()\n",
    "par6 = dict(mr6.params)\n",
    "\n",
    "plt.scatter(auto['horsepower'],auto['mpg'],color='black',label=\"data\")\n",
    "\n",
    "x = np.linspace(0,250,1000)\n",
    "y1 = par1[\"Intercept\"] + par1['horsepower']*x\n",
    "y2 = par2[\"Intercept\"] + par2['horsepower']*x + par2['I(horsepower ** 2.0)']*x**2\n",
    "y3 = par3[\"Intercept\"] + par3['horsepower']*x + par3['I(horsepower ** 2.0)']*x**2 + par3['I(horsepower ** 3.0)']*x**3\n",
    "y4 = par4[\"Intercept\"] + par4['horsepower']*x + par4['I(horsepower ** 2.0)']*x**2 + par4['I(horsepower ** 3.0)']*x**3 + par4['I(horsepower ** 4.0)']*x**4\n",
    "y5 = par5[\"Intercept\"] + par5['horsepower']*x + par5['I(horsepower ** -1.0)']*x**-1\n",
    "y6 = par6[\"Intercept\"] + par6['horsepower']*x + par6['I(horsepower ** -1.0)']*x**-1 + par6['I(horsepower ** -2.0)']*x**-2\n",
    "\n",
    "plt.plot(x,y1,label=\"degree 1\",linewidth=2)\n",
    "plt.plot(x,y2,label=\"degree 2\",linewidth=2)\n",
    "plt.plot(x,y3,label=\"degree 3\",linewidth=2)\n",
    "plt.plot(x,y4,label=\"degree 4\",linewidth=2)\n",
    "plt.plot(x,y5,label=\"degree -1\",linewidth=2)\n",
    "plt.plot(x,y6,label=\"degree -2\",linewidth=2)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('horsepower'); plt.ylabel('mpg')\n",
    "plt.ylim((0,50))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr5.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "As the model complexity increases, \n",
    "- the accuracy on the training data increases, but \n",
    "+ the generalizability of the model to the test set decreases. \n",
    "\n",
    "Our job is to find a model that is sufficiently complex to describe the training data, but not so complex that it isn't generalizable to new data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Class exercise: analysis of the credit dataset \n",
    "\n",
    "Next, let's use [Statsmodels](http://statsmodels.sourceforge.net/) to study a dataset related to credit cards.\n",
    "We'll use the 'Credit' dataset, available \n",
    "[here](http://www-bcf.usc.edu/~gareth/ISL/data.html). \n",
    "This dataset consists of some credit card information for 400 people. \n",
    "\n",
    "Of course, a *credit card* is a card issued to a person (\"cardholder\"), typically from a bank, that can be used as a method of payment. The card allows the cardholder to borrow money from the bank to pay for goods and services. Credit cards have a *limit*, the maximum amount you can borrow, which is determined by the bank. The limit is determined from information collected from the cardholder (income, age, ...) and especially (as we will see) the cardholders \"credit rating\".  The *credit rating* is an evaluation of the (1) ability of the cardholder to pay back the borrowed money and (2) the likelihood of the cardholder to defaulting on the borrowed money. \n",
    "\n",
    "Our focus will be on the use of regression tools to study this dataset. Ideally, we'd like to understand what factors determine *credit ratings* and *credit limits*. We can think about this either from the point of view of (1) a bank who wants to protect their investments by minimizing credit defaults or (2) a person who is trying to increase their credit rating and/or credit limit. \n",
    "\n",
    "A difficulty we'll encounter is including categorical data in regression models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from Credit.csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize and describe data\n",
    "#dtypes, value_counts, describe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The column names of this data are:  \n",
    "1. Income \n",
    "+ Limit  \n",
    "+ Rating  \n",
    "+ Cards\n",
    "+ Age  \n",
    "+ Education  \n",
    "+ Gender (categorial: M,F)\n",
    "+ Student (categorial: Y,N)\n",
    "+ Married (categorial: Y,N)\n",
    "+ Ethnicity (categorial: Caucasian, Asian, African American) \n",
    "+ Balance\n",
    "\n",
    "**Question:** What is wrong with the income data? How can it be fixed? \n",
    "\n",
    "The file 'Credit.csv' is a comma separated file. I assume a period was used instead of a comma to indicate thousands in income so it wouldn't get confused with the separating value? Or maybe this is a dataset from Europe? Or maybe the income is just measured in \\$1k units?  To change the income data, we can use the Pandas series 'map' function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix income data.  originally in units of $1k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the covariances in the data. (This is how the variables vary together.) There are two ways to do this:\n",
    "1. Quantitatively: Compute the correlation matrix. For each pair of variables, $(x_i,y_i)$, we compute \n",
    "$$\n",
    "\\frac{\\sum_i (x_i - \\bar x) (y_i - \\bar y)}{s_x s_y}\n",
    "$$ \n",
    "where $\\bar x, \\bar y$ are sample means and $s_x, s_y$ are sample variances. \n",
    "+ Visually: Make a scatter matrix of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# use the corr method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# use the scatter_matrix function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Observations:**\n",
    "1. Limit and Rating are highly correlated ($99.7\\%$)  \n",
    "+ Income strongly correlates with Limit ($79\\%$) and Rating ($79\\%$)\n",
    "+ Balance correlates with Limit ($86\\%$) and Rating ($86\\%$)\n",
    "+ There are \"weird stripes\" in some of the data. Why? \n",
    "+ Categorical information doesn't appear in this plot. Why? How can I visualize the categorical variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Categorical variables: Gender, Student, Married, Ethnicity\n",
    "\n",
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first regression model\n",
    "\n",
    "**Exercise** First regress Limit on Rating: \n",
    "$$\n",
    "\\text{Limit} = \\beta_0 + \\beta_1 \\text{Rating}. \n",
    "$$\n",
    "Since credit ratings are primiarily used by banks to determine credit limits, we expect that Rating is very predictive for Limit, so this regression should be very good. \n",
    "\n",
    "Use the 'ols' function from the statsmodels python library. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use statsmodels for a basic OLS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$credit limit = 14.8*rating - 542$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Predicting limit without rating \n",
    "\n",
    "Since Rating and Limit are almost the same variable, next we'll forget about Limit and just try to predict Rating from the real-valued variables (non-categorical variables): Income, Cards, Age, Education, Balance. \n",
    "\n",
    "**Exercise:** Develop a multilinear regression model to predict Rating. \n",
    "Interpret the results. \n",
    "\n",
    "For now, just focus on the real-valued variables (Income, Cards, Age, Education, Balance)\n",
    "and ignore the categorial variables (Gender, Student, Married, Ethnicity). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Which independent variables are good/bad predictors? \n",
    "\n",
    "**Observations:**\n",
    "1. Income and balance are best predictors\n",
    "+ Including other variables (Cards, Age, Education) doesn't increase $R^2$ by much. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Incorporating categorical variables into regression models\n",
    "\n",
    "We have four categorical variables (Gender, Student, Married, Ethnicity). How can we include them in a regression model? \n",
    "\n",
    "Let's start with a categorical variable with only 2 categories: Gender (Male, Female).\n",
    "\n",
    "Idea: Create a \"dummy variable\" that turns Gender into a real value: \n",
    "$$\n",
    "\\text{Gender_num}_i = \\begin{cases} \n",
    "1 & \\text{if $i$-th person is female} \\\\\n",
    "0 & \\text{if $i$-th person is male}\n",
    "\\end{cases}. \n",
    "$$\n",
    "Then we could try to fit a model of the form\n",
    "$$\n",
    "\\text{Income} = \\beta_0 + \\beta_1 \\text{Gender_num}. \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#use map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot credit scores for the various genders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Since the $p$-value for the Gender_num coefficient is very large, there is no support for the conclusion that there is a difference in credit card balance between genders.\n",
    "\n",
    "**Exercise**: Try to find a meaningful relationship in the data including one of the categorical variables (Gender, Student, Married), for example, Balance vs. Student, Credit vs. Married, etc... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#use corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What about a categorical variable with 3 categories? \n",
    "\n",
    "The Ethnicity variable takes three values: Caucasian, Asian, and African American. \n",
    "\n",
    "What's wrong with the following?  \n",
    "$$\n",
    "\\text{Ethnicity_num}_i = \\begin{cases} \n",
    "0 & \\text{if $i$-th person is Caucasian} \\\\\n",
    "1 & \\text{if $i$-th person is Asian} \\\\ \n",
    "2 & \\text{if $i$-th person is African American}\n",
    "\\end{cases}. \n",
    "$$\n",
    "\n",
    "Hint: Recall Nominal, Ordinal, Interval, Ratio variable types from Lecture 4 (Descriptive Statistics).\n",
    "\n",
    "We'll need more than one dummy variable:  \n",
    "$$\n",
    "\\text{Asian}_i = \\begin{cases} \n",
    "1 & \\text{if $i$-th person is Asian} \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}. \n",
    "$$\n",
    "$$\n",
    "\\text{Caucasian}_i = \\begin{cases} \n",
    "1 & \\text{if $i$-th person is Caucasian} \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}. \n",
    "$$\n",
    "The value with no dummy variable--African American--is called the *baseline*.\n",
    "\n",
    "We can use the *get_dummies* function to automatically get these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#get dummies\n",
    "pd.get_dummies(credit[\"Ethnicity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Exercise**: Can you find a relationship in the data involving the variable ethnicity? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# your code here \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
