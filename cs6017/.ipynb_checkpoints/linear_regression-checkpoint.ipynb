{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Data Science \n",
    "# Lecture 10: Linear Regression 1\n",
    "*COMP 5360 / MATH 4100, University of Utah, http://datasciencecourse.net/*\n",
    "\n",
    "In this lecutre, we'll discuss:\n",
    "* Simple linear regression (SLR)\n",
    "* Example: advertisement effects\n",
    "* Descriptive vs. inferential viewpoints \n",
    "* Multiple linear regression \n",
    "* Nonlinear relationships \n",
    "\n",
    "Recommended reading:\n",
    "* G. James, D. Witten, T. Hastie, and R. Tibshirani, An Introduction to Statistical Learning, Ch. 3 [digitial version available here](http://www-bcf.usc.edu/~gareth/ISL/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Regression \n",
    "\n",
    "*Linear regression* models the relationship between an independent (explanatory) variable $X$ and a (real-valued) dependent value $Y$.\n",
    "\n",
    "** Examples**\n",
    "<table style=\"width:60%\", align=\"left\">\n",
    "  <tr>\n",
    "    <th>explanatory variable, X</th>\n",
    "    <th>dependent variable, Y</th> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>square footage</td>\n",
    "    <td>house price</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>advertising dollars spent</td>\n",
    "    <td>profit</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>stress</td>\n",
    "    <td>lifespan</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>?</td>\n",
    "    <td>?</td> \n",
    "  </tr>  \n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple Linear Regression (SLR)\n",
    "\n",
    "** Data**: We have $n$ samples $(x_1, y_1), \\ (x_2, y_2),\\ldots,(x_n, y_n)$.\n",
    "\n",
    "** Model**: $y \\sim \\beta_0 + \\beta_1 x$ \n",
    "\n",
    "**Goal**: Find the best values of $\\beta_0$ and $\\beta_1$, denoted $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$, so that the prediction $y = \\hat{\\beta}_0 + \\hat{\\beta}_1 x$ \"best fits\" the data.\n",
    "\n",
    "![image](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/400px-Linear_regression.svg.png)\n",
    "\n",
    "**Theorem.** \n",
    "The best parameters in the *least squares sense* are:\n",
    "$$\n",
    "\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y}) }{\\sum_{i=1}^n (x_i - \\overline{x})^2}\n",
    "\\qquad \\textrm{and} \\qquad\n",
    "\\hat{\\beta}_0 = \\overline{y} -  \\hat{\\beta}_1 \\overline{x}. \n",
    "$$\n",
    "where $\\overline{x} = \\frac{1}{n} \\sum_{i=1}^n x_i$ and $\\overline{y} = \\frac{1}{n} \\sum_{i=1}^n y_i$. \n",
    "\n",
    "**Proof.** On board in class; see SLR.pdf.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple linear regresssion with python\n",
    "\n",
    "### Python packages for regression\n",
    "There are several different python packages that do regression:\n",
    "1. [statsmodels](http://statsmodels.sourceforge.net/) (Ported to Python from R)\n",
    "1. [scikit-learn](http://scikit-learn.org/) (Machine Learning)\n",
    "1. [SciPy](http://www.scipy.org/)\n",
    "1. ... \n",
    "\n",
    "\n",
    "Today, we'll look at both statsmodels and scikit-learn. One can use SciPy for linear regression, but its built-in functionality is comparitively limited. \n",
    "\n",
    "\n",
    "### Example dataset\n",
    "To illustrate linear regression, we'll use the 'Advertising' dataset from\n",
    "[here](http://www-bcf.usc.edu/~gareth/ISL/data.html)\n",
    "\n",
    "\n",
    "For 200 different ‘markets’ (think different cities), this dataset consists of the number of sales of a particular product as well as the advertising budget for different media: TV, radio, and newspaper. \n",
    "\n",
    "We’ll use linear regression to study the effect of advertising on sales. \n",
    "Here, sales is the dependent variable and the budgets are the independent variables. This might help inform or evaluate an advertising strategy for this product.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# imports and setup\n",
    "\n",
    "import scipy as sc\n",
    "from   scipy.stats import norm\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as sm\n",
    "from   sklearn import linear_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "advert = pd.read_csv( 'Advertising.csv', index_col=0 ) #load data\n",
    "advert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plot and describe the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter( x=advert['TV'],        y=advert['Sales'], c='r', marker='s', label='TV')\n",
    "plt.scatter( x=advert['Radio'],     y=advert['Sales'], c='b', marker='o', label='Radio')\n",
    "plt.scatter( x=advert['Newspaper'], y=advert['Sales'], c='k', marker='*', label='Newspaper')\n",
    "\n",
    "plt.legend( numpoints=1, loc=4 )\n",
    "plt.xlabel( 'Ad budget (Thousands of dollars)' )\n",
    "plt.ylabel( 'Sales (units of product)' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "advert.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Observations \n",
    "1. From the plot, it is clear that there is a relationship between the advertising budgets and sales. Basically, the more money spent, the larger the number of sales. \n",
    "+  The most money was spent on TV advertising. The amount for Radio and Newspaper is about the same in all markets, whereas the standard deviation for TV advertising is larger. \n",
    "\n",
    "## Questions\n",
    "1. How can we quantify the relationship between advertising and sales? Can we predict the effect of each ad media on sales? Is the relationship linear? \n",
    "+  Which of the different ad media (TV, Radio, Newspaper) are the most effective at generating sales? \n",
    "+  Are there interactions between the different ad media?\n",
    "\n",
    "First, let's just look at the **effect of TV advertising on sales**. We use the linear regression model\n",
    "$$\n",
    "Sales = \\beta_0 + \\beta_1 * TV.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ad_TV_ols = sm.ols( formula=\"Sales ~ TV\", data=advert ).fit() # ols == ordinary least squares\n",
    "ad_TV_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter( x=advert['TV'],y=advert['Sales'], c='k', marker='*',label='TV' )\n",
    "plt.plot( advert['TV'], ad_TV_ols.predict(), color='blue', linewidth=3 )\n",
    "\n",
    "_ = plt.xlabel( 'TV budget (Thousands of dollars)' )\n",
    "_ = plt.ylabel( 'Sales (Thousand units of product)' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Interpretation and discussion\n",
    "\n",
    "The intercept of the line is $\\hat{\\beta}_0 = 7.032$. This means that without any TV advertising, the model predicts that 7,032 units of product will be sold. \n",
    "\n",
    "The slope of the line is $\\hat{\\beta}_1 = 0.0475$. This means that the model predicts that for every additional $1k spent on TV advertising, an additional 47.5 units of product are sold. \n",
    "\n",
    "**So how good is this fit?** \n",
    "\n",
    "One way to measure the quality of the fit is to look at the sum of the squared residuals,\n",
    "$$\n",
    "SSR = \\sum_{i=1}^n (y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i)^2. \n",
    "$$\n",
    "Remember that SSR is the quantity that we minimized to find $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$ in the first place (We called it $J(\\beta_0,\\beta_1)$.) If this number is very small, then the model fits the data very well. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ad_TV_ols.ssr # Sum of Squared Residuals (Un-normalized residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "But how small is small?...good question. This number, SSR, is difficult to interpret by itself. A more easily interpretable number is the **$R^2$ value**. \n",
    "\n",
    "The $R^2$ value is an alternative way to measure how good of a fit the model is to the data. The benefit of the $R^2$ value over the SSR is that it is a proportion (takes values between 0 and 1) so it is easier to interpret what a *good* value is. We first define the residual sum of squares (SSR) and total sum of squares (TSS) by\n",
    "$$\n",
    "SSR = \\sum_{i=1}^n (y_i - \\hat\\beta_0 - \\hat\\beta_1 x_i)^2\n",
    "\\qquad \\text{and} \\qquad \n",
    "TSS = \\sum_{i=1}^n (y_i - \\bar y)^2. \n",
    "$$\n",
    "SSR measures the amount of variability left unexplained after the linear regression. TSS measures the total variance in the data. We compute the $R^2$ value as\n",
    "$$\n",
    "R^2 = 1 - \\frac{SSR}{TSS}.\n",
    "$$\n",
    "This is the proportion of the variance explained by the model. A model is good if the $R^2$ value is nearly one (the model explains all of the variance in the data). \n",
    "\n",
    "In our model, the value is $R^2 = 0.612$, which isn't bad. The model explains $61\\%$ of the variability in sales. \n",
    "\n",
    "*Note*: for linear regression, the $R^2$ value is the same as correlation, but the $R^2$ value more easily generalizes to more complicated regression models than correlation, so the $R^2$ value is typically considered instead of correlation.\n",
    "\n",
    "![image](http://imgs.xkcd.com/comics/linear_regression.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Repeating the simple linear regression with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "lr = linear_model.LinearRegression() # create a linear regression object\n",
    "\n",
    "# scikit-learn doesn't work as well with pandas, so we have to extract values \n",
    "xs = advert['TV'].values.reshape( advert['TV'].shape[0], 1 )\n",
    "ys = advert['Sales'].values.reshape( advert['Sales'].shape[0], 1 )\n",
    "\n",
    "#xs = advert['TV'].values.reshape( advert['TV'].shape[0], 1 )\n",
    "#ys = advert['Sales'].values.reshape( advert['Sales'].shape[0], 1 )\n",
    "\n",
    "lr.fit( X=xs, y=ys ) # X implies a matrix, so more than 1 list of Xs\n",
    "\n",
    "plt.scatter( xs, ys,  color='black')\n",
    "plt.plot( xs, lr.predict(xs), color='blue', linewidth=3 )\n",
    "\n",
    "plt.xlabel( 'TV budget (Thousands of dollars)' )\n",
    "plt.ylabel( 'Sales (Thousand units of product)' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hypothesis testing in linear regression\n",
    "\n",
    "In lecture 4, we introduced a distrinction between descriptive statistics and statistical inference. \n",
    "1. In descriptive statistics, one seeks just to describe the data. In the present setting, we have described how the response variable linearly depends on the predictor variable by minimizing the residual sum of squares (RSS). \n",
    "+ The statistical inference way of looking at this problem would be to suppose that there exists a ground truth population with $x$ and $y$ related by \n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x \n",
    "$$\n",
    "for some unknown values of $\\beta_0$ and $\\beta_1$. \n",
    "Our sampled data consists of points $(x_i, y_i)$ of the form \n",
    "$$\n",
    "y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i. \n",
    "$$\n",
    "Here $\\epsilon_i$ are random variable (say normally distributed) that we think of as \"error\" being introduced into the samples. The job of the statistician is to *infer* the values of $\\beta_0$ and $\\beta_1$ from the erroneous data.  \n",
    "\n",
    "This is precisely the setting we were in when determining wheter a coin was fair. There, we had a sample proportion of heads (analogous to the samples $(x_i,y_i)$ here.) We used the Central Limit Theorem to say that the variance (standard error) is given by\n",
    "$$\n",
    "SE(\\hat \\mu)^2 = \\sigma^2/n \n",
    "$$\n",
    "Using this value and assuming the null hypothesis (the coin is fair), we could evaluate the likelihood of obtaining a sample as extreme as the one obtained. \n",
    "\n",
    "In simple linear regression, we will take the null hypothesis to be\n",
    "$$\n",
    "H_0: \\text{There is no relationship between $x$ and $y$} \\iff \\beta_1 = 0 \n",
    "$$\n",
    "with alternative\n",
    "$$\n",
    "H_a: \\text{There is a relationship between $x$ and $y$}  \\iff \\beta_1 \\neq 0 \n",
    "$$\n",
    "We assume that $\\epsilon$ is a normal random variable with zero mean and variance $\\sigma^2$. Using similar ideas as above, the standard error for $\\hat \\beta_0$ and $\\hat \\beta_1$ (estimates of true parameters in this model) are computed to be \n",
    "$$\n",
    "SE(\\hat \\beta_0)^2 = \\sigma^2 \\left( \\frac{1}{n} + \\frac{\\bar x^2}{\\sum_{i=1}^n (x_i - \\bar x)^2} \\right) \n",
    "\\quad \\text{and} \\quad\n",
    "SE(\\hat \\beta_1)^2 =  \\frac{\\sigma^2}{\\sum_{i=1}^n (x_i - \\bar x)^2}\n",
    "$$\n",
    "\n",
    "\n",
    "For this hypothesis test, the test statistic is \n",
    "$$\n",
    "t = \\frac{ \\hat \\beta_1 - 0}{SE(\\hat \\beta_1)},\n",
    "$$\n",
    "which under the assumptions of the null hypothesis, is distributed according to the $t$ distribution with $n-2$ degrees of freedom. The $p$-value is computed as the probability of observing a value as extreme as $|t|$. A small $p$-value is interpreted to mean that there is an association between the independent and dependent variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### An experiment\n",
    "Before we go back and discuss the $p$-values for the advertising data, let's look at some synthetic data. We generate 100 random points according the model \n",
    "$$\n",
    "y = 3x + \\epsilon,\n",
    "$$\n",
    "where $\\epsilon$ is normally distributed with mean zero and standard deviation 2. The best fit is found and this process is repeated 1000 times over. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "f= lambda x: 3*x\n",
    "#def f(x): return 3*x\n",
    "x = np.linspace(-2,2,3).reshape(3,1)\n",
    "plt.figure(0)\n",
    "\n",
    "sample_size = 100\n",
    "betaOnes = []\n",
    "betaZeros = []\n",
    "for ii in range(1000):\n",
    "    # Create a set of random points... random X values, and the corresponding Y values + some more noise.\n",
    "    xp = norm.rvs(size=sample_size)\n",
    "    yp = f(xp)+norm.rvs(size=sample_size,scale=2)\n",
    "    \n",
    "    if ii == 1: plt.plot( xp, yp, 'bo' )\n",
    "\n",
    "    lr = linear_model.LinearRegression()\n",
    "    lr.fit(X=xp.reshape(100,1), y=yp)\n",
    "    plt.plot(x,lr.predict(x),color='blue',linewidth=1)\n",
    "    \n",
    "    # Collect the slopes \n",
    "    betaOnes.append(lr.coef_[0])\n",
    "    betaZeros.append(lr.intercept_)\n",
    "\n",
    "plt.plot(xp,f(xp),'k',linewidth=3)\n",
    "plt.xlim(-2,2)    \n",
    "plt.ylim(-10,10)    \n",
    "plt.title('Best fit lines for points generated from a random model')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(1)\n",
    "plt.hist(betaOnes, bins=40)\n",
    "plt.title('A histogram of estimates for beta_1')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(1)\n",
    "plt.hist(betaZeros, bins=40)\n",
    "plt.title('A histogram of estimates for beta_0')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "For the SLR model considered here, the $p$-values for both the intercept and the slope are very small. The probability of seeing obtaining these values is nearly zero, asuming $H_0$ is true. So, we reject the null hypothesis and say there is an association between TV advertising (independent variable) and sales (dependent variable). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other advertisement methods?  \n",
    "Recall that we not only know the ad budget for TV, but also Radio and Newspaper. \n",
    "\n",
    "Next, let's repeat the linear regression analysis for the other types of advertisements using statsmodels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ad_Radio_ols = sm.ols(formula=\"Sales ~ Radio\", data=advert).fit()\n",
    "ad_Radio_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ad_Newspaper_ols = sm.ols(formula=\"Sales ~ Newspaper\", data=advert).fit()\n",
    "ad_Newspaper_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(x=advert['TV'],y=advert['Sales'],c='r',marker='s',label='TV')\n",
    "plt.scatter(x=advert['Radio'],y=advert['Sales'],c='b',marker='o',label='Radio')\n",
    "plt.scatter(x=advert['Newspaper'],y=advert['Sales'],c='k',marker='*',label='Newspaper')\n",
    "plt.legend(numpoints=1,loc=4)\n",
    "\n",
    "plt.plot(advert['TV'],ad_TV_ols.predict(),c='r',linewidth=3)\n",
    "plt.plot(advert['Radio'],ad_Radio_ols.predict(),c='b',linewidth=3)\n",
    "plt.plot(advert['Newspaper'],ad_Newspaper_ols.predict(),c='k',linewidth=3)\n",
    "\n",
    "plt.xlabel('Ad budget (Thousands of dollars)')\n",
    "plt.ylabel('Sales (units of product)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Interpretation\n",
    "\n",
    "*So what is the most effective advertising media?*\n",
    "\n",
    "The slope for radio is largest, so you might argue that this is the most effective advertising media. For every additional \\$1k spent on Radio advertising, an additional 202 units of product are sold. (Compare to 54.7 for newspaper and 47.5 for TV.)\n",
    "\n",
    "On the other hand, the $R^2$ value for radio is just $33\\%$. So the model isn't explaining as much of the data as the model for TV advertising ($R^2 = 61\\%$), but is explaining more than the model for newspaper advertising ($R^2 = 5\\%$). \n",
    "\n",
    "The main problem with the approach here is that for each advertising media we look at, we're ignoring the ads in the other media. For example, in the model for TV advertising, \n",
    "$$\n",
    "Sales = \\beta_0 + \\beta_1 * TV,\n",
    "$$\n",
    "we're ignoring both Radio and Newspaper advertising. \n",
    "\n",
    "We need to take all three into account at once. Maybe we can construct a model that looks like \n",
    "$$\n",
    "Sales = \\beta_0 + \\beta_1 * TV + \\beta_2*Radio + \\beta_3*Newspaper. \n",
    "$$\n",
    "This is the idea behind Multiple Linear Regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "**Model:**\n",
    "$$\n",
    "Sales = \\beta_0 + \\beta_1 * TV + \\beta_2*Radio + \\beta_3*Newspaper. \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ad_all_ols = sm.ols(formula=\"Sales ~ TV + Radio + Newspaper\", data=advert).fit()\n",
    "ad_all_ols.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Interpretation\n",
    "\n",
    "Sepnding an additional \\$1,000  on radio adertising results in an increase in sales by 189 units. Radio is the most effective at method of advertising. \n",
    "\n",
    "In multilinear regression, the F-test is a way to test the null hypothesis,\n",
    "$$\n",
    "H_0 = \\textrm{all coefficients are zero.}\n",
    "$$\n",
    "In this case, we see that the $p$-value for the $F$-statistic is vanishingly small - indicating that our model is significant. \n",
    "\n",
    "Now let's consider the individual coefficients in the model and their $p$-values. Note that the coefficients for TV and Radio are approximately the same as for simple linear regression. The coefficient for Newspaper changed signficantly. Furthermore, note that the $p$-value is now very large $p=0.86$. There is not sufficient evidence to reject the null hypothesis that the Newspaper and Sales variables have no relationship. \n",
    "\n",
    "So then why did the simplie linear regression give that there is a relationship between Newspaper and Sales Variables? \n",
    "*Newspaper is actually a confounder!* (Remember the example where temperature is a confounder for pool deaths and ice creams sales.) Let's look at the correlations between the four variables. Recall that correlation between two variables is given by \n",
    "$$\n",
    "r_{x,y} = \\frac{ \\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar x) (y_i - \\bar y)}{s_x s_y}.\n",
    "$$\n",
    "Correlation is a number between −1 to +1 and measures how much the two variables vary together. \n",
    "\n",
    "Plotted below is also a scatter matrix plot which is a good way of visualizing the correlations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(advert.corr())\n",
    "pd.plotting.scatter_matrix(advert, figsize=(10, 10), diagonal='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The correlation between Newspaper and Radio is 0.35, which implies that in markets where the company advertised using Radio, they also advertised using newspaper. Thus, the influence of Radio on Sales can be incorrectly attributed to Newspaper advertisements! \n",
    "\n",
    "This leads us to the following linear regression model, where we forget about Newspaper advertisements:\n",
    "$$\n",
    "\\text{Sales} = \\beta_0 + \\beta_1 * \\text{TV\\_budget} + \\beta_2 * \\text{Radio\\_budget} \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ad_TR_ols = sm.ols(formula=\"Sales ~ TV + Radio\", data=advert).fit()\n",
    "ad_TR_ols.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "This model performs pretty well. It accounts for $R^2 = 90\\%$ of the variance in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(xs=advert['TV'], ys=advert['Radio'], zs=advert['Sales'])\n",
    "\n",
    "x = np.linspace(advert['TV'].min(), advert['TV'].max(), 100)\n",
    "y = np.linspace(advert['Radio'].min(), advert['Radio'].max(), 100)\n",
    "X,Y = np.meshgrid(x,y)\n",
    "par = dict(ad_TR_ols.params)\n",
    "Z = par[\"Intercept\"] + par[\"TV\"]*X + par[\"Radio\"]*Y \n",
    "surf = ax.plot_surface(X, Y, Z,cmap=cm.Greys, alpha=0.2)\n",
    "\n",
    "ax.view_init(35,-71)\n",
    "\n",
    "ax.set_xlabel('TV budget')\n",
    "ax.set_ylabel('Radio budget')\n",
    "ax.set_zlabel('Sales')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nonlinear relationships\n",
    "\n",
    "We can consider the interaction between TV and Radio advertising in the model, by taking \n",
    "$$\n",
    "\\text{Sales} = \\beta_0 + \\beta_1 * \\text{TV\\_budget} + \\beta_2*\\text{Radio\\_budget} + \\beta_3 \\text{TV\\_budget} *\\text{Radio\\_budget}. \n",
    "$$\n",
    "The rational behind the last term is that perhaps spending $x$ on television advertising and $y$ on radio advertising leads to more sales than simply $x+y$. In marketing this is known as the *synergy effect* and in statistics it is known as the *interaction effect*.\n",
    "\n",
    "**Note**: even though the relationship between the independent and dependent variables is nonlinear, the model is still linear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ad_NL = sm.ols(formula=\"Sales ~ TV + Radio + TV*Radio\", data=advert).fit()\n",
    "ad_NL.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "This model is really excellent. All of the $p$-values are small and $R^2 = 97\\%$ of the variability in the data is accounted for by the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(xs=advert['TV'], ys=advert['Radio'], zs=advert['Sales'])\n",
    "\n",
    "x = np.linspace(advert['TV'].min(), advert['TV'].max(), 100)\n",
    "y = np.linspace(advert['Radio'].min(), advert['Radio'].max(), 100)\n",
    "X,Y = np.meshgrid(x,y)\n",
    "par = dict(ad_NL.params)\n",
    "Z = par[\"Intercept\"] + par[\"TV\"]*X + par[\"Radio\"]*Y + par[\"TV:Radio\"]*X*Y\n",
    "surf = ax.plot_surface(X, Y, Z,cmap=cm.Greys, alpha=0.2)\n",
    "\n",
    "ax.view_init(25,-71)\n",
    "\n",
    "ax.set_xlabel('TV budget')\n",
    "ax.set_ylabel('Radio budget')\n",
    "ax.set_zlabel('Sales')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## A word of caution on overfitting (more on this later)\n",
    "\n",
    "It is tempting to include a lot of terms in the regression, but this is problematic (think $p$-hacking.) A useful model will  *generalize* beyond the data given to it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RT = sm.ols(formula=\"Newspaper ~ TV + Radio\", data=advert).fit()\n",
    "N_RT.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=advert['TV'],y=advert['Newspaper'],c='r',marker='s',label='TV')\n",
    "plt.scatter(x=advert['Radio'],y=advert['Newspaper'],c='b',marker='o',label='Radio')\n",
    "plt.legend(numpoints=1,loc=4)\n",
    "\n",
    "plt.xlabel('Ad budget (Thousands of dollars)')\n",
    "plt.ylabel('Newspaper sales (Thousands of dollars)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "8fcd46d531329f49b73a0948faa8aed429eb8dafd35203d9948e8358a307ba0e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
