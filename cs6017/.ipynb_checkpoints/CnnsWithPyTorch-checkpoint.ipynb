{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Nets\n",
    "\n",
    "Here we'll use the PyTorch library to train a neural net based classifier on a higher-res version of the handwritten digit dataset\n",
    "\n",
    "You can install what we need with `/usr/local/bin/pip3 install torch torchvision`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5),(0.5))]) #convert from images to tensors\n",
    "\n",
    "mnist_train = torchvision.datasets.MNIST( \"./mnist\", train=True, download=True, transform=transform )\n",
    "mnist_test  = torchvision.datasets.MNIST( \"./mnist\", train=False, download=True, transform=transform )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the data.  The toTensor part is converting from a \"PyImage\" format to a \"Tensor\" which is basically just a numpy multi-dimensional array.\n",
    "\n",
    "* The Normalize means we rescale the tensors so that the mean value is 0.5.\n",
    "* Neural nets tend to be really sensitive to input scale/normalization issues.\n",
    "  * If you're having trouble training a network, you might consider trying to normalize your data before using the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: For some reason the data is already broken into training and test data for us...\n",
    "\n",
    "print( \"Training data:\" )\n",
    "print( mnist_train.data.shape ) # 60,000 example imagers, 28x28  (x1...???)\n",
    "print( mnist_train.targets.shape )\n",
    "\n",
    "print( \"\\nTesting data:\" )\n",
    "print( mnist_test.data.shape )\n",
    "print( mnist_test.targets.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 60k training images, 28x28 pixels, and 10k testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the first few images in the dataset...\n",
    "plt.figure( figsize= (10, 10) )\n",
    "\n",
    "for ii in np.arange( 25 ):\n",
    "    plt.subplot( 5, 5, ii+1 )\n",
    "    plt.imshow( mnist_train.data[ii, :, :], cmap='Greys',interpolation='none' )\n",
    "    plt.title( int(mnist_train.targets[ii]) )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are a lot higher res than the ones we were playing with in Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define our neural net.  \n",
    "\n",
    "This is using the PyTorch Model API, where we write the network out as a class with a constructor and a \"forward\" method.  The \"forward\" method describes the layers in the network and how they're used.  Based on what we do here, PyTorch will automatically compute the gradient for us, so we can train our weights.\n",
    "\n",
    "Note: Took one of the image training example nets and modified/tweaked it...\n",
    "\n",
    "We'll start with 2 convolution layers with max pooling in between and then 3 dense layers after that (I think this is probably overkill for this dataset, but it works well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        c1Out = 6 # convolution layer 1 will output 6 \"images\": one for each filter it trains\n",
    "        c2Out = 16 # similarly for the 2nd convolution layer\n",
    "        self.conv1 = nn.Conv2d( 1, c1Out, 3 ) # 1-D input, c1Out outputs, filter size 3x3 pixels\n",
    "        \n",
    "        # (28-2) x (28 -2) x c1Out outputs  # \"-2\" because 3x3 mask loses the 1st/last row/column\n",
    "        \n",
    "        self.pool = nn.MaxPool2d( 2, 2 ) # down sample 2x2 blocks to 1 value\n",
    "        \n",
    "        # 13*13*c1Out\n",
    "        \n",
    "        self.conv2 = nn.Conv2d( c1Out, c2Out, 3 ) # Inputs comes from conv1, specify our #outputs, use 3x3 blocks again\n",
    "        \n",
    "        # (13-2)*(13 -2)*c2Out\n",
    "        # pool again\n",
    "        # (11/2)*(11/2)*c2Out = 5x5 x c2Out\n",
    "        \n",
    "        #this is tricky.  The convolutions each shave 1 pixel off around the border, and then the\n",
    "        #max pools reduce the number of pixels by 4\n",
    "        self.pooledOutputSize = c2Out * 5 * 5 # 16 outputs per image whose size has been reduced\n",
    "        self.fc1 = nn.Linear( self.pooledOutputSize, 120 )\n",
    "        self.fc2 = nn.Linear( 120, 84 )\n",
    "        self.fc3 = nn.Linear( 84, 10 ) # 10 outputs at the end\n",
    "\n",
    "    ################################################################################\n",
    "    # Take an image (or images) and run it through all stages of the net:\n",
    "    #    \n",
    "    def forward( self, x ): # \"batch\" of images\n",
    "        # x is 4D tensor:  (batch size, width, height, #channels (1, grayscale image))\n",
    "        # after conv1:  (batch size, width adjusted, height adjusted, conv1 # outputs)\n",
    "        # after max pool: (batch size, width/2, height/2, conv1 # outputs)\n",
    "        \n",
    "        # print(x.shape) # During creation / debugging, getting the shape of layers correct is challenging... so display them.\n",
    "        #x = F.relu(self.conv1(x))\n",
    "        x = self.conv1(x)\n",
    "        # print(x.shape)\n",
    "        x = F.relu(x)\n",
    "        # print(x.shape)\n",
    "        x = self.pool(x)\n",
    "        # print(x.shape)\n",
    "\n",
    "        # Split into 2 lines above\n",
    "        #x = self.pool(F.relu(self.conv1(x)))  #apply convolution filter, then run it through relu activation function\n",
    "        x = self.pool(F.relu(self.conv2(x))) #ditto\n",
    "        #print(x.shape) #uncomment to see the size of this layer.  It helped me figure out what pooledOutputSize shoudl be\n",
    "\n",
    "        # Flatten: turn the 5x5xc2Out array into a single 1xN array.  The dense layers expect a 1D thing\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        # x = x.view(x.shape[0], -1)  #equivalent ways of reshaping the data to be 1D\n",
    "        # x = x.view(batch_size( x.shape[0]) , -1)\n",
    "        x = F.relu(self.fc1(x)) #apply dense layer 1\n",
    "        x = F.relu(self.fc2(x)) #and dense layer 2, using ReLU activation\n",
    "        x = self.fc3(x) #final dense layer.  No activation function on this\n",
    "        return x\n",
    "    \n",
    "    #compute the output size after our convolution layers\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train( model, epochs ): # One epoch uses the entire training set (one batch at a time) - 60,000 images in this case\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss() # this is a way of measuring error (loss) for classification that takes the\n",
    "                                      # \"confidence\" of a prediction into account.  High confidence, correct predictions are low cost, \n",
    "                                      # high confidence, wrong predictions are high cost, medium confidence predictions have cost\n",
    "\n",
    "    # use the ADAM optimizer to find the best weights\n",
    "    optimizer = optim.Adam( model.parameters(), lr= 1e-4 ) \n",
    "    \n",
    "    #this loads data and gets it in the right format for us\n",
    "    trainloader = torch.utils.data.DataLoader( mnist_train, batch_size=8,\n",
    "                                               shuffle=True, num_workers=0 )\n",
    "\n",
    "    for epoch in range( epochs ): # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate( trainloader, 0 ):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "\n",
    "            inputs, labels = data\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs) #predict the output with some training data\n",
    "            loss = criterion(outputs, labels) #see how well we did\n",
    "\n",
    "            loss.backward() #see how to change the weights to do better\n",
    "            optimizer.step() #and actually change the weights\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "def evaluate( model ):  \n",
    "    #load some test data\n",
    "    testloader = torch.utils.data.DataLoader( mnist_test, batch_size=8,\n",
    "                                              shuffle=True, num_workers=0 )\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad(): # <- Since we are not training, the model does not need to calculate gradients\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = model( images )\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Just do a coarse evaluation... how many did we predict correcly?\n",
    "    print( 'Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note: On my home (older PC), this takes 3-ish minutes to run...\n",
    "print( \"Training...\" )\n",
    "train( net, 4 )\n",
    "\n",
    "print( \"Evaluating...\" )\n",
    "evaluate( net )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a different network.  Use more convolution layers and fewer dense layers, so fewer weights overall\n",
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        c1Out = 4\n",
    "        c2Out = 8\n",
    "        c3Out = 16\n",
    "        self.conv1 = nn.Conv2d(1, c1Out, 3) #1-D input, 5 outputs, filter size 3x3 pixels\n",
    "        self.pool = nn.MaxPool2d(2, 2) #downsample 2x2 blocks to 1 value\n",
    "        self.conv2 = nn.Conv2d(c1Out, c2Out, 3) #5 inputs (# outputs from conv 1), 5 outputs, 3x3 blocks\n",
    "        self.conv3 = nn.Conv2d(c2Out, c3Out, 3)\n",
    "        self.pooledOutputSize = c3Out*1*1 # 16 outputs per image whose size has been reduced\n",
    "        self.fc1 = nn.Linear(self.pooledOutputSize, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        #self.fc3 = nn.Linear(32, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net2 = Net2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"Training Net Version 2...\" )\n",
    "train( net2, 8 )\n",
    "\n",
    "print( \"Evaluating...\" )\n",
    "evaluate( net2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1Weights = net2.conv1.weight.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "for i in range(conv1Weights.shape[0]): #for each filter we trained\n",
    "    fig.add_subplot(2,2,i + 1)\n",
    "    plt.imshow(conv1Weights[i,:,:,:].reshape(3,3), cmap='Greys',interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2Weights = net2.conv2.weight.detach().numpy()\n",
    "print(conv2Weights.shape)\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "for i in range(conv2Weights.shape[0]): #for each filter we trained\n",
    "    for j in range(conv2Weights.shape[1]): #since there were many input channels, theres more\n",
    "        fig.add_subplot(8,4,i*4 + j + 1)\n",
    "        plt.imshow(conv2Weights[i,j,:,:].reshape(3,3), cmap='Greys',interpolation='none')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "8fcd46d531329f49b73a0948faa8aed429eb8dafd35203d9948e8358a307ba0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
