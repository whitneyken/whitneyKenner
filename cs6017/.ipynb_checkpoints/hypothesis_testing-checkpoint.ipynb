{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "dac6427e-b8df-46f9-bfd3-b24427a73993"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Data Science \n",
    "# Lecture 8: Hypothesis testing and statistical inference\n",
    "Adapted from notes for *COMP 5360 / MATH 4100, University of Utah, http://datasciencecourse.net/*\n",
    "\n",
    "In this lecture, we'll cover \n",
    "* Hypothesis testing\n",
    "* Central limit theorem\n",
    "* A/B testing\n",
    "\n",
    "Suggested reading:\n",
    "[WIRED article on A/B testing](http://www.wired.com/2012/04/ff_abtesting/)\n",
    "\n",
    "Suggested listening:\n",
    "[Planet Money Episode 669: A or B](https://www.npr.org/sections/money/2015/12/11/459412925/episode-669-a-or-b)\n",
    "\n",
    "Further reading: Jay L. Devore, Probability and Statistics for Engineering and the Sciences, 9th ed. Cengage Learning (2016) Ch. 8 and 9.\n",
    "\n",
    "For a more complete treatment, take Math 3070 (Applied Statistics I).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#imports and setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from scipy.stats import bernoulli\n",
    "from scipy.stats import binom\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import t\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap Lecture 4: Descriptive vs. Inferential Statistics \n",
    "\n",
    "*Descriptive statistics* quantitatively describes or summarizes features of a dataset. \n",
    "\n",
    "*Inferential statistics* attempts to learn about the population from which the data was sampled. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap Lecture 4:  discrete random variables\n",
    "\n",
    "*Discrete random variables* take discrete values with preassigned probabilities described by a probaility mass function (PMF). If $X$ is the random variable and $f(k)$ is the PMF, we say \"the probability that $X$ takes value $k$ is given by $f(k)$\" and write\n",
    "$$\n",
    "\\textrm{Prob}(X=k) = f(k).\n",
    "$$\n",
    "\n",
    "### Bernoulli distribution\n",
    "A Bernoulli random variable can take the values $k=0$ or $1$ and has PMF\n",
    "$$\n",
    "f(k) = \\begin{cases} p & k=1 \\\\ 1-p & k = 0 \\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "Some facts about Bernoulli variables: \n",
    "* mean is $p$\n",
    "* variance is $p(1-p)$\n",
    "\n",
    "**Example:** The Bernoulli distribution with $p=0.5$ describes a 'fair' coin toss where 1 and 0  represent \"heads\" and \"tails\", respectively. If the coin is unfair, then we would have that $p\\neq 0.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Binomial distribution\n",
    "\n",
    "A binomial r.v. takes values $k=0,1,\\ldots,n$, with a probability given by the pmf \n",
    "$$\n",
    "f(k) = \\binom{n}{k} p^k (1-p)^{n-k}.\n",
    "$$\n",
    "Here, $\\binom{n}{k} = \\frac{n!}{k!(n-k)!}$ in the binomial coefficient that describes how many ways there are to choose a subset of $k$ elements, disregarding their order, from a set of $n$ elements.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "n =10\n",
    "p = 0.5\n",
    "f = lambda k: binom.pmf(k, n=n,p=p)\n",
    "\n",
    "x = np.arange(n+1);\n",
    "plt.bar(x, f(x))\n",
    "plt.title(\"The probability mass function for a Binomial random variable\")\n",
    "plt.xlim([0,n])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Some facts about the binomial distribution:\n",
    "- A binomial random variable is just the sum of $n$ Bernoulli random variables. You can think of it as summarizing the resutls of $n$ coin flips by just keeping track of the total number of heads.\n",
    "- The mean is  $np$\n",
    "- The variance is  $np(1âˆ’p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Poisson distribution\n",
    "You also saw the Poisson random variable in the homework, which is another example of a discrete random variable. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap Lecture 4:  continuous random variables\n",
    "\n",
    "A *continuous random variable* can take any real value, but some numbers are more likely than others. The probability is given by the *probability density function (PDF)*, which is analogous to the PMF for discrete random variables. If f(x) is the PDF for the random variable $X$, then the probability that $X$ takes the value in the interval $[a,b]$ is given by \n",
    "\n",
    "$$\n",
    "\\textrm{Prob}(X\\in[a,b]) = \n",
    "\\int_a^b f(x) dx.\n",
    "$$\n",
    "This is just the area under the curve for this interval.\n",
    "\n",
    "### Example: Normal (Gaussian) distribution \n",
    "\n",
    "The *probability density function (PDF)* for a normal (Gaussian) random variable is\n",
    "$$\n",
    "f(x) = \\frac{1}{\\sqrt{ 2 \\pi \\sigma^2 }}\n",
    "e^{ - \\frac{ (x - \\mu)^2 } {2 \\sigma^2} }.\n",
    "$$\n",
    "This is sometimes referred to as the 'bell curve'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "mu = 0 # mean\n",
    "sigma = 1 # standard deviation \n",
    "x = np.arange(mu-4*sigma,mu+4*sigma,0.001);\n",
    "pdf = norm.pdf(x,loc=mu, scale=sigma)\n",
    "plt.title(\"The probability density function for a normal random variable\")\n",
    "plt.plot(x, pdf, linewidth=2, color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Some facts about the normal distribution:\n",
    "- The mean is $\\mu$\n",
    "- The variance is  $\\sigma^2$\n",
    "\n",
    "To compute the integral \n",
    "$$\n",
    "\\textrm{Prob}(X\\in[a,b]) = \n",
    "\\int_a^b f(x) dx,\n",
    "$$\n",
    "it is useful to define the *cumulative distribution function* (CDF)\n",
    "$$\n",
    "F(x) = \\int_{-\\infty}^x f(x) dx.\n",
    "$$\n",
    "Then we can write \n",
    "$$\n",
    "\\int_a^b f(x) dx =\n",
    "\\int_{-\\infty}^b f(x) dx  - \\int_{-\\infty}^a f(x) dx =\n",
    "F(b) - F(a).\n",
    "$$\n",
    "This is convenient because we know longer have to evaluate an integral! However, there isn't a nice way to write $F(x)$ for the normal distribution in terms of elementary functions. So we just think about $F(x)$ as a known function that we can easily compute using python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "mu = 0 # mean\n",
    "sigma = 1 # standard deviation \n",
    "x = np.arange(mu-4*sigma,mu+4*sigma,0.001);\n",
    "cdf = norm.cdf(x,loc=mu, scale=sigma)\n",
    "plt.title(\"The cumulative density function for a normal random variable\")\n",
    "plt.plot(x, cdf, linewidth=2, color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Exercise \n",
    "Interpet the following in terms of normal random variables:\n",
    "- $\\int_{-\\infty}^1 f(x) dx = F(1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "norm.cdf( 1, loc=mu, scale=sigma )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- $\\int_{-1}^1 f(x) dx = F(1) - F(-1)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "norm.cdf( 1, loc=mu, scale=sigma ) - norm.cdf( -1, loc=mu, scale=sigma ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Note that $\\int_{-\\infty}^\\infty f(x) dx = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "norm.cdf( sc.inf, loc=mu, scale=sigma )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "\n",
    "**Remark:** There are many other continous random variables, but in this class we'll only consider normal random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hypothesis testing\n",
    "\n",
    "Suppose we have a coin and we want to determine whether or not it is 'fair'. We could flip it many, many times and count how many heads we obtain. If the fraction of heads is approximately $0.5$, we might argue that the coin is fair. \n",
    "\n",
    "This is an example of statistical inference. We are trying to determine something about the coin from samples of coin flips. \n",
    "\n",
    "Let's say we flip a coin $n=1000$ times. If the coin is fair, the outcome is described by the Binomial distribution with $p=0.5$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "f = lambda k: binom.pmf( k, n=1000,p=0.5 )\n",
    "\n",
    "x = np.arange( 1001 )\n",
    "plt.plot( x, f(x), '.b' )\n",
    "plt.plot( 545, f(545), 'or', markersize=10 )\n",
    "plt.title( \"The probability mass function for a Binomial random variable\" )\n",
    "plt.xlim( [0,1001] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Suppose that in our experiment, we saw $545$ heads. The probability of this occuring is \n",
    "f(k = 545):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "value = binom.pmf( 545, n=1000, p=0.5 )\n",
    "\n",
    "print( \"%.4f%%\" % ( value * 100 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = binom.pmf( 500, n=1000, p=0.5 )\n",
    "print( \"500 of 1000: %.2f%%\" % ( value * 100 ) )\n",
    "\n",
    "# Percentage of \"outside\" results shrinks drastically as N increases:\n",
    "# value = binom.pmf( 4, n=10, p=0.5 ) \n",
    "# print( \"4 of 10:     %.2f%%\" % ( value * 100 ) )\n",
    "# value = binom.pmf( 400, n=1000, p=0.5 ) \n",
    "# print( \"400 of 1000: %.10f%%\" % ( value * 100 ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "In hypothesis testing, the more important question is: what is the probability of seeing a value as extreme or more extreme than the value that we observed? \n",
    "\n",
    "I would say that any result $\\leq 455$ or $\\geq 545$ is 'as or more extreme'. Why?\n",
    "\n",
    "So the probability of seeing as extreme of an outcome is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "s = sum( binom.pmf( np.arange(0,456), n=1000, p=0.5) ) + sum( binom.pmf( np.arange(545,1001), n=1000, p=0.5 ) )\n",
    "print( \"Any of 456- or 545+ out of 1000: %.2f%%\" % (s*100) )\n",
    "print( \"1-s: %.2f%%\" % ( (1-s)*100 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can alternatively use the CMF to do she summation for us:\n",
    "value = 2 * binom.cdf( 455, n=1000, p=0.5 ) # Multiply by 2 because the binomial distribution is symmetric.\n",
    "print( \"%.2f%%\" % ( value * 100 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So the likelihood of seeing so few heads (or tails) is just $0.49\\%$. So it is very unlikely that if the coin were fair, we would see this result! Maybe so unlikely that we would declare that the coin is unfair? This is the idea behind **hypothesis testing**. \n",
    "\n",
    "**Note**: I didn't say that it is unlikely that the coin itself is unfair. Only if it were to be fair, it would be unlikely to see this result. \n",
    "\n",
    "In *hypothesis testing*, we make a null hypothesis, written $H_0$. In this case, the null hypothesis is\n",
    "\n",
    "$$H_0: \\text{the coin is fair, i.e., $p=0.5$}.$$\n",
    "\n",
    "The alternative hypothesis, $H_a$, is typically the hypothesis that the researcher wants to validate. In this case, $H_a$ is that the coin is unfair, i.e., $p\\neq 0.5$. \n",
    "\n",
    "We also choose a *significance level* for the test, $\\alpha$, traditionally $1\\%$ or $5\\%$. \n",
    "In this case, let's choose a significance level of $\\alpha = 1\\%$. \n",
    "\n",
    "We then perform an experiment. In this case, we flip the coin 1000 times and count the number of heads (in this case 545). \n",
    "\n",
    "Finally, assuming the null hypothesis is true, we compute how how likely it is to see a number that is at least as far from the expected value as the number obtained. In our case, this is $0.49\\%$. The is called the *p-value*. Since $p=0.49\\%$ is smaller than the chosen significance level, $\\alpha = 1\\%$, we reject the null hypothesis and declare the coin to be unfair.  \n",
    "\n",
    "Some comments about the p-value:\n",
    "\n",
    "1. A p-value is a probability calculated assuming that $H_0$ is true. \n",
    "2. The smaller the p-value, the stronger the evidence against $H_0$.\n",
    "3. **Warning:** A p-value is not the probability that the null hypothesis is true or false. It is the probability that an erroneous conclusion is reached. In this example, it is the probability that the coin actually is fair and we just happened to see an outcome as extreme as 545 heads.\n",
    "\n",
    "To avoid computing sums (as above) and to 'normalize' the above procedure, it is useful to introduce the *Central Limit Thoerem*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Central Limit Theorem \n",
    "\n",
    "One of the reasons that the normal distribution is **so important** is the following theorem. \n",
    "\n",
    "**Central Limit Theorem.** Let $\\{X_1,\\ldots, X_n\\}$ be a sample of $n$ random variables chosen identically and independently from a distribution with mean $\\mu$ and finite variance $\\sigma^2$. If $n$ is 'large', then \n",
    "- the sum of the variables $\\sum_{i=1}^n X_i$ is also a random variable and is approximately **normally** distributed with mean $n\\mu$ and variance $n\\sigma^2$ and\n",
    "- the mean of the variables $\\frac{1}{n}\\sum_{i=1}^n X_i$ is also a random variable and is approximately **normally** distributed with mean $\\mu$ and variance $\\frac{\\sigma^2}{n}$.\n",
    "\n",
    "How can we use the central limit theorem (CLT)? \n",
    "\n",
    "Recall that a binomial random variable is the sum of $n$ bernoulli random variables. So the CLT tells us that if $n$ is large, binomial random variables will be distributed approximately normally. That is, if we flip a coin many times, the number of heads that we're likely to see is described by a normal distribution. This provides a different (easier) way to answer the question: How unlikely is it to flip a fair coin 1000 times and see 545 heads? \n",
    "\n",
    "Suppose we flip a fair ($p=0.5$) coin 1000 times. \n",
    "\n",
    "*Question:* How many heads do we expect to see? \n",
    "\n",
    "The CLT says that the number of heads (= sum of Bernoulli r.v. = binomial r.v.) is approximately normally distributed with mean \n",
    "$$ \n",
    "n\\mu = np = 1000*0.5 = 500 \n",
    "$$\n",
    "and variance \n",
    "$$ \n",
    "n \\sigma^2 = np(1-p) = 1000*0.5*0.5 = 250. \n",
    "$$\n",
    "\n",
    "Let's do an experiment to see how good the CLT is for Bernoulli random variables. We'll call flipping a fair coin n=1,000 times and counting the number of heads a \"simulation\". Recall that the outcome is precisely a binomial random variable with n=1,000 and p = 0.5. We'll do 10,000 simulations and then compare the histogram of the binomial random variables and the normal distribution predicted by the CLT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "n = 1000\n",
    "p = 0.5\n",
    "bin_vars = binom.rvs( n=n, p=p, size=10000 )\n",
    "\n",
    "plt.hist( bin_vars, bins='auto', density=True )\n",
    "\n",
    "mu = n*p \n",
    "sigma = np.sqrt( n*p*(1-p) )\n",
    "xs = np.arange( mu-4*sigma, mu+4*sigma, 0.1 )\n",
    "pdf = norm.pdf( xs, loc=mu, scale=sigma )\n",
    "plt.plot( xs, pdf, linewidth=2, color='k' )\n",
    "\n",
    "_ = plt.title(\"A comparison between the histogram of binomial random \\n variables and the normal distribution predicted by the CLT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So what is the likelihood of flipping a coin 1000 times and seeing an event less extreme as 545 heads? \n",
    "\n",
    "Note: F(x) == Cumulative Distribution Function (CDF).   f(c) == probability density function\n",
    "\n",
    "The CLT tells us that this is approximately \n",
    "$$\n",
    "\\int_{455}^{545} f(x) dx = F(545) - F(455).\n",
    "$$\n",
    "\n",
    "This is something that we can easily evaluate using the cumulative distribution function (CDF). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "n = 1000\n",
    "p = 0.5\n",
    "mu = n*p\n",
    "sigma = np.sqrt(n*p*(1-p))\n",
    "print(norm.cdf(545, loc=mu, scale=sigma) - norm.cdf(455, loc=mu, scale=sigma))\n",
    "\n",
    "# a plot illustrating the integral \n",
    "x = np.arange(mu-4*sigma,mu+4*sigma,0.001);\n",
    "plt.plot(x, norm.pdf(x, loc=mu, scale=sigma), linewidth=2, color='k')\n",
    "x2 = np.arange(455,545,0.001)\n",
    "plt.fill_between(x2, y1= norm.pdf(x2,loc=mu, scale=sigma), facecolor='red', alpha=0.5)\n",
    "plt.xlim([mu-4*sigma,mu+4*sigma])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So again, we see that $99.6\\%$ of the time, we would see an event less extreme than 545 heads.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: \"Freshman 15\": Fact or Fiction\n",
    "\n",
    "This example was taken from Devore, pp.314-315. \n",
    "\n",
    "\"A common belief among the lay public is that body weight increases after entry into college, and the phrase 'freshman 15' has been coined to describe the 15 pounds that students presumably gain over their freshman year.\"\n",
    "\n",
    "Let $\\mu$ denote the true average weight gain in the first year of college. We take the null hypothesis to be\n",
    "$$\n",
    "H_0: \\mu \\geq 15\n",
    "$$\n",
    "so that the alternative hypothesis is that the average weight gain in the first year of college is less than 15 lbs. \n",
    "\n",
    "We set a signifnicance level of, say, $\\alpha = 1\\%$. \n",
    "\n",
    "We suppose a random sample of $n$ students is selected, their weights (before and after the first year of college) are measured, and the sample mean $\\bar{x}$ and sample standard deviation $s$ are computed. An article in the journal Obesity (2006) cites that for a sample of $n=137$ students, the sample mean weight gain was $\\bar{x}=2.42$ lb and with a sample standard deviation of $s=5.72$ lb. \n",
    "\n",
    "We will compute a statistic called a \"One sample t-Test\" statistic using the hypothesized mean, sample mean, and sample standard deviation.\n",
    "\n",
    "t = (sample mean - true mean) / (sample standard deviation / sqrt(sample size))\n",
    "\n",
    "We expect t is distributed as a standard normal distribution ( mean = 0, standard deviation = 1)\n",
    "\n",
    "We compute the probability of getting the t-statistic from our sample by looking at the CDF of the normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sampleMean = 2.42\n",
    "trueMean = 15  # Hypothesized\n",
    "sampleSize = 137\n",
    "sampleStdDev = 5.72\n",
    "\n",
    "# We are \"transforming\" the above data into a single \"test statistic\".  \n",
    "# Based on \"t\" (the test statistic value), we calculate the p-value.\n",
    "\n",
    "t = (sampleMean - trueMean) / (sampleStdDev / np.sqrt(sampleSize))\n",
    "print( t )\n",
    "\n",
    "# Remember that we assume \"t\" came from a normal distribution...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the P-Value\n",
    "# The CDF tells us how likely t is.  # Note: Scale == Std Dev, Loc == Mean\n",
    "norm.cdf( t, loc=0, scale=1 )\n",
    "\n",
    "# Try H0: u >= 3 -- Remember, we are hoping to disprove this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what the P value would look like for different mean weight gain values\n",
    "\n",
    "means = np.linspace( 0, 20 ) # Average weight gains\n",
    "ts = (means - trueMean)/(sampleStdDev / np.sqrt(sampleSize))\n",
    "ps = norm.cdf( ts, loc = 0, scale = 1 )\n",
    "plt.plot( means, ps )\n",
    "\n",
    "# This is an interesting exploratory approach, but not for real science.\n",
    "# If we look at these values and \"nudge\" things (for a new sampling) to get a new P-value,\n",
    "#    This is called \"P-hacking\" which is bad science.\n",
    "# Note: if the measured average weight gain is less than ~13 pounds, the true average wait gain is not 15 pounds. \n",
    "# Note: At exactly 15 pounds, we see a P value of .5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The p-value is practically zero, much less than the significance level! The data very strongly contradicts the null hypothesis. We reject the null hypothesis, $H_0$, and conclude that the 'freshman 15' is fiction! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Gender in Utah, the z-test\n",
    "\n",
    "Let's try to determine whether the following statement is true: \n",
    "$$\n",
    "\\text{In Utah, there are 50\\% men and 50\\% women.}\n",
    "$$\n",
    "\n",
    "We model this as a Bernoulli variable with female = 1, male = 0. \n",
    "\n",
    "We take as null hypothesis that the proportion of women is $p=0.5$,\n",
    "$$\n",
    "H_0: p = 0.5\n",
    "$$\n",
    "We set the significance level as $\\alpha = 0.05$. \n",
    "\n",
    "Now, we need a sample... we'll use a survey of students in a graudate CS course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class_gender = pd.read_csv( 'SurveyGenderResponse.csv' )\n",
    "\n",
    "print( class_gender.head() )\n",
    "print( class_gender.describe() )\n",
    "\n",
    "# It is more convenient to map \n",
    "# Female -> 1\n",
    "# Male -> 0\n",
    "di = { 'Female': 1, 'Male': 0 }\n",
    "class_gender['Gender'].replace( di, inplace=True )\n",
    "\n",
    "print( class_gender.head() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Record the number of female students, size of survey, and percent of female students, and sample standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "num_f = class_gender['Gender'].sum()\n",
    "print( \"Number of females:\", num_f )\n",
    "\n",
    "n = class_gender.size\n",
    "print( \"Number of students: \", n )\n",
    "\n",
    "x_bar = class_gender['Gender'].mean()\n",
    "print( \"Average:\", x_bar )\n",
    "\n",
    "s = class_gender['Gender'].std()\n",
    "print( \"Std Dev:\", s )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "According to our survery, 17 of 62 people are women, so we have $\\bar x = 0.27$. \n",
    "\n",
    "To proceed, we conduct a **z-test**, which is the same as we did in the previous example, except now we use the normalized z-values, \n",
    "$$\n",
    "z = \\frac{\\bar{x} - .5}{s/\\sqrt{n}}. \n",
    "$$\n",
    "The CLT (Central Limit Theorem) can be used to show that the $z$ score is distributed according to the \"standard\" normal distribution with mean $\\mu=0$ and standard deviation $\\sigma = 1$.\n",
    "\n",
    "The z-value is generally called a **test statistic**. Every type of hypothesis test has its own test statistic. The z-test is just one example of a hypothesis test, see many more listed [here](https://en.wikipedia.org/wiki/Test_statistic#Common_test_statistics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "z = (x_bar - .5) / ( s / np.sqrt(n) ) \n",
    "print( \"%.3f\" % z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "How unlikely is it to see a z-score less than $z = -3.95$? \n",
    "$$\n",
    "\\text{p-value} = \\int_{-\\infty}^z f(x) dx = F(z)\n",
    "$$\n",
    "We can compute this using the function norm.cdf with default arguments 'loc=0' and 'scale=1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "p_value = norm.cdf( z )\n",
    "print( \"%.6f\" % p_value )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Under the assumption of the null hypothesis, we would only see a sample size this extreme $p=0.004\\%$ of the time. Since the $p$ value is less than our chosen signficance level, $\\alpha = 5\\%$, we reject the null hypothesis and conclude that in Utah there are fewer than 50% women. \n",
    "\n",
    "**What's wrong with this finding?**\n",
    "\n",
    "The proceedure we used for the hypothesis test was correct.\n",
    "\n",
    "However, the students were **not randomly sampled from the population**! If we wanted to address this question, we'd have to account for the fact that the survey was taken at a university in a STEM course, both of which bias the sample (in opposite directions). This is one reason that polling (inference from survey data) is very challenging. \n",
    "\n",
    "The 2010 census shows that the percentage of females in Utah is 49.8%.\n",
    "http://www.census.gov/quickfacts/table/SEX205210/49,4967000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What to do for smaller sample sizes? Student's t-test\n",
    "\n",
    "When $n$ is small, the Central Limit Theorem can no longer be used. In this case, if the samples are drawn from an approximately normal distribution, then the correct distribution to use is called the Student's t distribution with $\\nu = n-1$ degrees of freedom. The probability density function (pdf) for the student's t distribution is not pretty (Google it!) but it is built into scipy, so we can compare the student's t-test to the normal distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# There is some trouble with this package for some python versions.\n",
    "# If it doesn't work, don't worry about it\n",
    "\n",
    "from ipywidgets import interact \n",
    "from scipy import stats\n",
    "\n",
    "samp_mean = 0\n",
    "samp_std_dev = 1\n",
    "\n",
    "xs = np.linspace( samp_mean - ( 4 * samp_std_dev ), samp_mean + ( 4 * samp_std_dev ), 1000 )\n",
    "\n",
    "def compare_distributions( sample_size ):\n",
    "\n",
    "    pdf1 = norm.pdf( xs, loc=samp_mean, scale=samp_std_dev/np.sqrt(sample_size) )\n",
    "    pdf2 = stats.t.pdf( xs, df=sample_size-1,loc=samp_mean, scale=samp_std_dev/np.sqrt(sample_size) )\n",
    "\n",
    "    plt.plot( xs, pdf1, linewidth=2, color='k',label='normal distribution pdf' )\n",
    "    plt.plot( xs, pdf2, linewidth=2, color='r',label='t distribution pdf' )\n",
    "\n",
    "    plt.xlim( xs.min(),x.max() )\n",
    "    plt.ylim( 0,2 )\n",
    "\n",
    "    plt.legend()\n",
    "    \n",
    "_ = interact( compare_distributions, sample_size=(2,20,1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The student's t distribution has \"heaveier tails\" than the normal distribution. For a sample size greater than $\\approx 20$, the normality assumption is generally accepted as reasonable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Types of error in hypothesis testing \n",
    "\n",
    "In hypothesis testing, there are two types of errors. A *type I error* is the incorrect rejection of a true null hypothesis (a \"false positive\"). A *type II error* is incorrectly accepting a false null hypothesis (a \"false negative\"). Depending on the application, one error can be more consequential than the other. \n",
    "\n",
    "![](InferenceErrors.png)\n",
    "$\\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad$ \n",
    "source: [wikipedia](https://en.wikipedia.org/wiki/Type_I_and_type_II_errors)\n",
    "\n",
    "The probability of making a type I (false positive error) is the significance level $\\alpha$. \n",
    "\n",
    "**Examples**\n",
    "\n",
    "**(1)** In drug testing, we take the null hypothesis (H0): \"This drug has no effect on the disease.\" A type I error detects an effect (the drug cures the disease) that is not present. A type II error fails to detect an effect (the drug cures the disease) that is present. \n",
    "\n",
    "**(2)** In a trial, we take the null hypothesis (H0): \"This man is innocent.\" A type I error convicts an innocent person. A type II error lets a guilty person go free. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## P hacking\n",
    "\n",
    "Recall that the p-value measures how extreme the observation is and is compared to the significance level. Some comments about the p-value:\n",
    "1. A p-value is a probability calculated assuming that $H_0$ is true. \n",
    "+ The smaller the p-value, the stronger the evidence against $H_0$.\n",
    "+ A p-value is not the probability that the null hypothesis is true or false. It is the probability that an erroneous conclusion is reached.\n",
    "\n",
    "Recently the *misuse* of hypothesis testing (p-values) has raised considerable controversy. Basically, if you do enough hypothesis tests, eventually you'll have a Type I (false positive) error. This is a real problem in a world with tons of data in which it is easy to do many, many hypothesis tests automatically. \n",
    "\n",
    "You can read more about 'P hacking' here:\n",
    "\n",
    "- R. Nuzzo, Scientific method: Statistical errors, Nature (2014) [link](https://doi.org/10.1038/506150a)\n",
    "\n",
    "- J. Cohen, The Earth is Round (p<0.05), American Psychologist (1994) [link](https://doi.org/10.1037/0003-066x.49.12.997)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A/B testing\n",
    "A/B testing is a method of comparing two or more versions of an advertisement, webpage, app, etc. We set up an experiment where the variants are shown to users at random and statistical analysis is used to determine which is best. AB testing is the *de facto* test for many business decisions.  \n",
    "\n",
    "**Example.** A/B testing was extensively used by President Obama during his 2008 and 2012 campaigns to  develop \n",
    "* optimized fund-raising strategies,  \n",
    "* get-out-the-vote programs that would be most beneficial, and \n",
    "* target ads to the most susceptible audiences. \n",
    "\n",
    "Learn more here:\n",
    "[Wired story on A/B testing](http://www.wired.com/2012/04/ff_abtesting/)\n",
    "and \n",
    "[Planet Money Episode 669: A or B](https://www.npr.org/sections/money/2015/12/11/459412925/episode-669-a-or-b)\n",
    "\n",
    "**Example.** Suppose your company is developing an advertisement. The art department develops two internet ads: \"Ad A\" and \"Ad B\". Your job is to figure out which is better. \n",
    "\n",
    "You decide to do an experiment: You use Google ads to randomly show 1000 internet users Ad A and 1000 internet users Ad B. \n",
    "\n",
    "It turns out that 500 Ad A viewers click on the ad while 550 Ad B viewers click on the ad? Obviously Ad B did better, but is the difference \"significant\" enough to say that Ad B is better? Or perhaps Ad B just got lucky in this test? \n",
    "\n",
    "In your homework, youâ€™ll answer this question. More generally, this is a question about the difference between population proportions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistical inference for a difference between population proportions\n",
    "We consider comparing the population proportions of two different populations. \n",
    "\n",
    "We make the following definitions:\n",
    "- $N_A$ is the number of surveyed people from population $A$  \n",
    "- $n_A$ is the number of successes from population $A$\n",
    "- $p_A = n_A/N_A$ is the proportion of successes from population $A$\n",
    "\n",
    "Similarly, we define \n",
    "- $N_B$ is the number of surveyed people from population $B$  \n",
    "- $n_B$ is the number of successes from population $B$\n",
    "- $p_B = n_B/N_B$ is the proportion of successes from population $B$\n",
    "\n",
    "We make the null hypothesis:\n",
    "$$\n",
    "H_0\\colon \\text{$p_A$ and $p_B$ are the same, that is, } p_A - p_B = 0.\n",
    "$$\n",
    "That is, the proportion of successes in the two populations is the same. \n",
    "\n",
    "We'll take it as a fact (see Devore Ch. 9.4 or Math 3070) that: \n",
    "- $n_A/N_A$ is approximately a normal random variable with mean $p_A$ and variance $\\sigma_A^2 = p_A(1-p_A)/N_A$ \n",
    "- $n_B/N_B$ is approximately a normal random variable with mean $p_B$ and variance $\\sigma_B^2 = p_B(1-p_B)/N_B$\n",
    "- $n_A/N_A - n_B/N_B$ is approximately a normal random variable with mean $\\mu = 0$ and variance $\\sigma^2 = \\sigma_A^2 + \\sigma_B^2$. \n",
    "- The test statistic called the *two-proportion z-value* \n",
    "$$\n",
    "Z = \\frac{p_A - p_B}{\\sqrt{\\hat{p} \\hat{q} \\left( \\frac{1}{N_A} + \\frac{1}{N_B} \\right)}}.\n",
    "$$\n",
    "is approximately  distributed according to the standard normal distribution when $H_0$ is true. Here $\\hat{p} = \\frac{N_A}{N_A + N_B}p_A + \\frac{N_B}{N_A + N_B}p_B$ and $\\hat{q} = 1-\\hat{p}$. \n",
    "\n",
    "From the data, we estimate the mean, $\\mu$, to be  $p_A - p_B$. \n",
    "\n",
    "## Example: 1954 Salk polio-vaccine experiment\n",
    "\n",
    "In 1954, polio was widespread and a new vaccine of unknown efficacy was introduced. To test the efficacy, in a double-blind study, two groups of children were give injections: one contained the vaccine and the other contained a placebo. \n",
    "\n",
    "Let $p_A$ and $p_B$ be the proportions of the children, having received the placebo and vaccine injections, respectively, to contract polio. We formulate the null hypothesis that \n",
    "$$\n",
    "H_0\\colon p_A - p_B \\leq 0,\n",
    "$$\n",
    "that is, the vaccine is not effective.\n",
    "The alternative hypothesis is that \n",
    "$$\n",
    "H_a\\colon p_A - p_B >0, \n",
    "$$\n",
    "that is, a vaccinated child is less likely to contract polio than a child receiving the placebo.\n",
    "\n",
    "We choose a significance level of $\\alpha = 0.01$. \n",
    "\n",
    "An experiment was conducted with the following results: \n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\text{Placebo:} \\quad N_A = 201,229, \\quad n_A = 110 \\\\\n",
    "&\\text{Vaccine:} \\quad N_B = 200,745, \\quad n_B = 33.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "nA = 110\n",
    "NA = 201229\n",
    "pA = nA/NA\n",
    "muA = pA\n",
    "sigmaA = np.sqrt(pA*(1-pA)/NA)\n",
    "\n",
    "nB = 33\n",
    "NB = 200745\n",
    "pB = nB/NB\n",
    "muB = pB\n",
    "sigmaB = np.sqrt(pB*(1-pB)/NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Now we perform the hypothesis test and see what the probability of the outcome is under the assumption of the null hypothesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "phat = NA*pA/(NA+NB) + NB*pB/(NA+NB)\n",
    "qhat = 1-phat\n",
    "\n",
    "z = (pA - pB)/np.sqrt(phat*qhat*(1/NA + 1/NB)) \n",
    "print(z)\n",
    "\n",
    "p_value = 1-norm.cdf(z)\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The probability that an erroneous conclusion is reached, under the assumption of the null hypothesis, is $6.6\\times10^{-11}$, way less than the significance level, $\\alpha$. We reject the null hypothesis and declare that the vaccine is more effective than a placebo! "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "8fcd46d531329f49b73a0948faa8aed429eb8dafd35203d9948e8358a307ba0e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "nbpresent": {
   "slides": {
    "006f01ca-e160-4faa-ad02-2f873362ca99": {
     "id": "006f01ca-e160-4faa-ad02-2f873362ca99",
     "prev": "e60ea09b-1474-49b0-9ea6-2e803b335693",
     "regions": {
      "88222835-28de-4a0f-895e-303024baf060": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "e6a51e7a-d63e-4187-8899-bfbf03f8a4b6",
        "part": "whole"
       },
       "id": "88222835-28de-4a0f-895e-303024baf060"
      }
     }
    },
    "2ba6955d-8be2-4ce3-ae98-f3b3695e4832": {
     "id": "2ba6955d-8be2-4ce3-ae98-f3b3695e4832",
     "prev": "35a7a5a6-f0c3-4b68-9579-e5840160a87d",
     "regions": {
      "63b4b5f3-c348-418c-aabf-932d5fdbcc1c": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "883076a7-1c6e-492f-b9d2-0b8550b5c31f",
        "part": "whole"
       },
       "id": "63b4b5f3-c348-418c-aabf-932d5fdbcc1c"
      }
     }
    },
    "2d5e1e8f-2e26-415e-8d8d-9229f2dc1244": {
     "id": "2d5e1e8f-2e26-415e-8d8d-9229f2dc1244",
     "prev": "9ba8c8c8-59a7-4776-84cb-084e5b0a2317",
     "regions": {
      "44582fec-116b-475d-9793-ad29580b7fc2": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4992f285-654f-485e-81ef-8a6ae18cad34",
        "part": "whole"
       },
       "id": "44582fec-116b-475d-9793-ad29580b7fc2"
      }
     }
    },
    "35a7a5a6-f0c3-4b68-9579-e5840160a87d": {
     "id": "35a7a5a6-f0c3-4b68-9579-e5840160a87d",
     "prev": "c7291188-b014-4fcb-83bc-f1ea035ee4c9",
     "regions": {
      "cbc80f26-e933-4d90-9dfd-e55a3dc339ba": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "558af430-f4c0-4be9-b1ef-afce5fccd0fa",
        "part": "whole"
       },
       "id": "cbc80f26-e933-4d90-9dfd-e55a3dc339ba"
      }
     }
    },
    "3ecd0fe6-e75f-4362-a6e7-e5273e12058e": {
     "id": "3ecd0fe6-e75f-4362-a6e7-e5273e12058e",
     "prev": "2d5e1e8f-2e26-415e-8d8d-9229f2dc1244",
     "regions": {
      "eac20970-b45c-4073-a596-cdb2a974fe23": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "de60c848-d1fb-478d-a736-0ebe21762a24",
        "part": "whole"
       },
       "id": "eac20970-b45c-4073-a596-cdb2a974fe23"
      }
     }
    },
    "4e939c85-e2b3-48b3-b2df-389bc0ca7dd0": {
     "id": "4e939c85-e2b3-48b3-b2df-389bc0ca7dd0",
     "prev": "9807c9b8-54cd-4a78-b50d-1a6e9f7ff066",
     "regions": {
      "ddc97209-2f2f-409d-953c-a9a83dec6738": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "674ee724-0165-40c5-9296-83db8305fa4c",
        "part": "whole"
       },
       "id": "ddc97209-2f2f-409d-953c-a9a83dec6738"
      }
     }
    },
    "95bf00f9-fc2a-4478-bd48-fb66078e061f": {
     "id": "95bf00f9-fc2a-4478-bd48-fb66078e061f",
     "prev": "b9fa7815-a205-4ea6-9076-1289b96670cf",
     "regions": {
      "dd7aef1b-3f05-47a5-bc5f-274809d2c21d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "61e1167e-99ef-4b5d-b717-07a46077a091",
        "part": "whole"
       },
       "id": "dd7aef1b-3f05-47a5-bc5f-274809d2c21d"
      }
     }
    },
    "966d5c12-49ef-4129-aecb-b183804ecd19": {
     "id": "966d5c12-49ef-4129-aecb-b183804ecd19",
     "prev": "3ecd0fe6-e75f-4362-a6e7-e5273e12058e",
     "regions": {
      "ff0704a2-f662-4a03-9874-5613f4634956": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a6fd92a3-b57e-45c5-b216-f9f475baf8ce",
        "part": "whole"
       },
       "id": "ff0704a2-f662-4a03-9874-5613f4634956"
      }
     }
    },
    "9807c9b8-54cd-4a78-b50d-1a6e9f7ff066": {
     "id": "9807c9b8-54cd-4a78-b50d-1a6e9f7ff066",
     "prev": "966d5c12-49ef-4129-aecb-b183804ecd19",
     "regions": {
      "9e037b47-3fb5-4a60-b69c-ad3b282807a1": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "b79fa570-8c08-4820-a035-2a00bfae1a9b",
        "part": "whole"
       },
       "id": "9e037b47-3fb5-4a60-b69c-ad3b282807a1"
      }
     }
    },
    "9ba8c8c8-59a7-4776-84cb-084e5b0a2317": {
     "id": "9ba8c8c8-59a7-4776-84cb-084e5b0a2317",
     "prev": "9e2b6ffd-bec2-4027-93e8-64b63e770378",
     "regions": {
      "45bb0df9-937a-48a6-882b-346a1253250c": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "be5bedf1-b9ed-4caa-bc3e-6c390df97946",
        "part": "whole"
       },
       "id": "45bb0df9-937a-48a6-882b-346a1253250c"
      }
     }
    },
    "9e2b6ffd-bec2-4027-93e8-64b63e770378": {
     "id": "9e2b6ffd-bec2-4027-93e8-64b63e770378",
     "prev": "e9d31a55-0862-44ec-bd48-d74167655985",
     "regions": {
      "7a7c6996-8117-42ce-8093-318b84bd052b": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "95b34ac1-b36d-492d-84f9-adafb2d57ace",
        "part": "whole"
       },
       "id": "7a7c6996-8117-42ce-8093-318b84bd052b"
      }
     }
    },
    "ae354c9e-1384-4f31-8e03-5c96f3988bf4": {
     "id": "ae354c9e-1384-4f31-8e03-5c96f3988bf4",
     "prev": null,
     "regions": {
      "9e57ef10-c941-41de-93da-812357c7ec21": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "dac6427e-b8df-46f9-bfd3-b24427a73993",
        "part": "whole"
       },
       "id": "9e57ef10-c941-41de-93da-812357c7ec21"
      }
     }
    },
    "b9fa7815-a205-4ea6-9076-1289b96670cf": {
     "id": "b9fa7815-a205-4ea6-9076-1289b96670cf",
     "prev": "ae354c9e-1384-4f31-8e03-5c96f3988bf4",
     "regions": {
      "cc19ec36-3caa-4666-86e7-2bd1d9cb03b8": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c7392535-4666-41a5-a68a-7306dccd6cd8",
        "part": "whole"
       },
       "id": "cc19ec36-3caa-4666-86e7-2bd1d9cb03b8"
      }
     }
    },
    "c7291188-b014-4fcb-83bc-f1ea035ee4c9": {
     "id": "c7291188-b014-4fcb-83bc-f1ea035ee4c9",
     "prev": "006f01ca-e160-4faa-ad02-2f873362ca99",
     "regions": {
      "3fa8900b-1ee2-4625-8e0b-a8a52d95390d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a912604c-786a-448e-a908-397f28b46a13",
        "part": "whole"
       },
       "id": "3fa8900b-1ee2-4625-8e0b-a8a52d95390d"
      }
     }
    },
    "e60ea09b-1474-49b0-9ea6-2e803b335693": {
     "id": "e60ea09b-1474-49b0-9ea6-2e803b335693",
     "prev": "4e939c85-e2b3-48b3-b2df-389bc0ca7dd0",
     "regions": {
      "3df2ec23-ba8a-4b76-b6af-2a4aa219da46": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "06d04c6d-90a4-441d-9d6e-4f719490e12e",
        "part": "whole"
       },
       "id": "3df2ec23-ba8a-4b76-b6af-2a4aa219da46"
      }
     }
    },
    "e9d31a55-0862-44ec-bd48-d74167655985": {
     "id": "e9d31a55-0862-44ec-bd48-d74167655985",
     "prev": "95bf00f9-fc2a-4478-bd48-fb66078e061f",
     "regions": {
      "cc6bd695-e238-4250-8822-ffea3f82f544": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "86c3f014-9535-48f0-95a2-df74d16eaa69",
        "part": "whole"
       },
       "id": "cc6bd695-e238-4250-8822-ffea3f82f544"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
